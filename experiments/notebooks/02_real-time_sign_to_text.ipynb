{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144a387b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# WLASL LSTM TRAINING - Real-time Sign Language Recognition\n",
    "# ==========================================\n",
    "# Train MediaPipe + LSTM model on WLASL isolated signs for continuous real-time detection\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"âœ… Imports loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18134e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 1. HELPER FUNCTIONS (Run this first!)\n",
    "# ==========================================\n",
    "\n",
    "import tensorflow as tf\n",
    "from scipy import interpolate\n",
    "\n",
    "# Target sequence length for LSTM\n",
    "TARGET_FRAMES = 30\n",
    "\n",
    "# Landmark counts (MediaPipe Holistic)\n",
    "N_FACE = 468\n",
    "N_POSE = 33\n",
    "N_LEFT_HAND = 21\n",
    "N_RIGHT_HAND = 21\n",
    "TOTAL_LANDMARKS = N_FACE + N_POSE + N_LEFT_HAND + N_RIGHT_HAND  # 543\n",
    "\n",
    "def load_parquet_landmarks(file_path):\n",
    "    \"\"\"Load landmarks from parquet file.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_parquet(file_path)\n",
    "        return df\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def parquet_to_array(df):\n",
    "    \"\"\"Convert parquet DataFrame to (T, 543, 3) array.\"\"\"\n",
    "    if df is None or len(df) == 0:\n",
    "        return None\n",
    "    \n",
    "    n_frames = df['frame'].max() + 1\n",
    "    \n",
    "    # Initialize array with zeros\n",
    "    data = np.zeros((n_frames, TOTAL_LANDMARKS, 3), dtype=np.float32)\n",
    "    \n",
    "    # Fill in landmarks\n",
    "    for _, row in df.iterrows():\n",
    "        frame_idx = int(row['frame'])\n",
    "        lm_idx = int(row['landmark_index'])\n",
    "        lm_type = row['type']\n",
    "        \n",
    "        # Map type to global index\n",
    "        if lm_type == 'face':\n",
    "            global_idx = lm_idx\n",
    "        elif lm_type == 'left_hand':\n",
    "            global_idx = N_FACE + lm_idx\n",
    "        elif lm_type == 'pose':\n",
    "            global_idx = N_FACE + N_LEFT_HAND + lm_idx\n",
    "        elif lm_type == 'right_hand':\n",
    "            global_idx = N_FACE + N_LEFT_HAND + N_POSE + lm_idx\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        if global_idx < TOTAL_LANDMARKS and frame_idx < n_frames:\n",
    "            data[frame_idx, global_idx, 0] = row['x']\n",
    "            data[frame_idx, global_idx, 1] = row['y']\n",
    "            data[frame_idx, global_idx, 2] = row['z']\n",
    "    \n",
    "    return data\n",
    "\n",
    "def resample_sequence(data, target_len=TARGET_FRAMES):\n",
    "    \"\"\"Resample sequence to target length using linear interpolation.\"\"\"\n",
    "    current_len = data.shape[0]\n",
    "    \n",
    "    if current_len == target_len:\n",
    "        return data\n",
    "    \n",
    "    # Create interpolation indices\n",
    "    old_indices = np.linspace(0, current_len - 1, current_len)\n",
    "    new_indices = np.linspace(0, current_len - 1, target_len)\n",
    "    \n",
    "    # Interpolate each landmark and coordinate\n",
    "    resampled = np.zeros((target_len, TOTAL_LANDMARKS, 3), dtype=np.float32)\n",
    "    \n",
    "    for lm in range(TOTAL_LANDMARKS):\n",
    "        for coord in range(3):\n",
    "            f = interpolate.interp1d(old_indices, data[:, lm, coord], kind='linear')\n",
    "            resampled[:, lm, coord] = f(new_indices)\n",
    "    \n",
    "    return resampled\n",
    "\n",
    "print(\"âœ… Helper functions defined!\")\n",
    "print(f\"   Target frames: {TARGET_FRAMES}\")\n",
    "print(f\"   Total landmarks: {TOTAL_LANDMARKS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b150c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 1. EXPLORE WLASL LANDMARKS DATA\n",
    "# ==========================================\n",
    "\n",
    "# Path to WLASL landmarks\n",
    "WLASL_DIR = \"/kaggle/input/wlasl2000-landmarks/wlasl_landmarks\"\n",
    "\n",
    "# List all parquet files\n",
    "parquet_files = glob.glob(f\"{WLASL_DIR}/*.parquet\")\n",
    "print(f\"ðŸ“Š Total parquet files: {len(parquet_files)}\")\n",
    "\n",
    "# Load one sample to inspect structure\n",
    "sample_file = \"/kaggle/input/wlasl2000-landmarks/wlasl_landmarks/00336.parquet\"\n",
    "print(f\"\\nðŸ” Inspecting sample file: {sample_file}\")\n",
    "\n",
    "df_sample = pd.read_parquet(sample_file)\n",
    "print(f\"\\nðŸ“‹ DataFrame shape: {df_sample.shape}\")\n",
    "print(f\"ðŸ“‹ Columns: {list(df_sample.columns)}\")\n",
    "print(f\"\\nðŸ“‹ First 10 rows:\")\n",
    "print(df_sample.head(10))\n",
    "\n",
    "print(f\"\\nðŸ“‹ Data types:\")\n",
    "print(df_sample.dtypes)\n",
    "\n",
    "print(f\"\\nðŸ“‹ Unique values:\")\n",
    "if 'type' in df_sample.columns:\n",
    "    print(f\"   Types: {df_sample['type'].unique()}\")\n",
    "if 'frame' in df_sample.columns:\n",
    "    print(f\"   Frames: {df_sample['frame'].min()} to {df_sample['frame'].max()}\")\n",
    "    print(f\"   Total frames: {df_sample['frame'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def196b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 2. LOAD WLASL-100 WORD MAPPINGS\n",
    "# ==========================================\n",
    "\n",
    "# Load the correct label mapping (100 words from WLASL)\n",
    "LABEL_MAPPING_PATH = \"/kaggle/input/wlasl200-mapping/label_mapping.json\"\n",
    "\n",
    "print(f\"ðŸ“– Loading WLASL-100 label mapping: {LABEL_MAPPING_PATH}\")\n",
    "with open(LABEL_MAPPING_PATH, 'r') as f:\n",
    "    label_data = json.load(f)\n",
    "\n",
    "gloss_to_label = label_data['gloss_to_label']\n",
    "label_to_gloss = label_data['label_to_gloss']\n",
    "num_classes = label_data['num_classes']\n",
    "\n",
    "print(f\"\\nâœ… Loaded label mapping!\")\n",
    "print(f\"ðŸ“Š Number of classes: {num_classes}\")\n",
    "print(f\"ðŸ“Š Total words: {len(gloss_to_label)}\")\n",
    "\n",
    "print(f\"\\nðŸ“ First 20 words:\")\n",
    "for i, word in enumerate(list(gloss_to_label.keys())[:20], 1):\n",
    "    label = gloss_to_label[word]\n",
    "    print(f\"   {i:2d}. {word:20s} â†’ Label {label}\")\n",
    "\n",
    "print(f\"\\nðŸ“ Last 10 words:\")\n",
    "for i, word in enumerate(list(gloss_to_label.keys())[-10:], 91):\n",
    "    label = gloss_to_label[word]\n",
    "    print(f\"   {i:2d}. {word:20s} â†’ Label {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2da2d86",
   "metadata": {},
   "source": [
    "# ðŸŽ¯ Strategy: Train LSTM on 100 Words\n",
    "\n",
    "## âœ… What We Have:\n",
    "- **100 words** from WLASL (accident, africa, all, apple, ...)\n",
    "- **~11,980 parquet files** with landmarks\n",
    "- **64 frames per video** (need to resample to 30)\n",
    "- **Landmarks format:** frame, type, landmark_index, x, y, z\n",
    "\n",
    "## ðŸŽ¯ Next Steps:\n",
    "1. **Load all videos** for our 100 words\n",
    "2. **Resample** from 64 frames â†’ 30 frames\n",
    "3. **Build LSTM model** (3 LSTM layers + Dense)\n",
    "4. **Train** (20-40 mins on GPU)\n",
    "5. **Export weights** for local webcam inference\n",
    "\n",
    "**Run cells 0-3 first to verify the data, then continue!** ðŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759ef797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 5. CREATE VIDEO-TO-WORD MAPPING (CORRECT VERSION)\n",
    "# ==========================================\n",
    "\n",
    "print(\"ðŸ“– Loading WLASL_v0.3.json (full dataset)...\")\n",
    "\n",
    "WLASL_FULL = \"/kaggle/input/wlasl-processed/WLASL_v0.3.json\"\n",
    "\n",
    "with open(WLASL_FULL, 'r') as f:\n",
    "    wlasl_full = json.load(f)\n",
    "\n",
    "print(f\"âœ… Loaded WLASL_v0.3.json\")\n",
    "print(f\"   Type: {type(wlasl_full)}\")\n",
    "\n",
    "# Check structure\n",
    "if isinstance(wlasl_full, list):\n",
    "    print(f\"   Total entries: {len(wlasl_full)}\")\n",
    "    print(f\"\\nðŸ” Sample entry:\")\n",
    "    print(json.dumps(wlasl_full[0], indent=2)[:500])\n",
    "    \n",
    "    # Create mapping: video_id â†’ word\n",
    "    print(f\"\\nðŸ”— Creating video_id â†’ word mapping...\")\n",
    "    \n",
    "    video_to_word = {}\n",
    "    word_to_videos = {}\n",
    "    \n",
    "    for entry in tqdm(wlasl_full, desc=\"Processing WLASL entries\"):\n",
    "        word = entry.get('gloss', None)\n",
    "        \n",
    "        # Only process words in our 100-word list\n",
    "        if word and word in gloss_to_label:\n",
    "            instances = entry.get('instances', [])\n",
    "            \n",
    "            for instance in instances:\n",
    "                video_id = instance.get('video_id', None)\n",
    "                if video_id:\n",
    "                    video_to_word[video_id] = word\n",
    "                    if word not in word_to_videos:\n",
    "                        word_to_videos[word] = []\n",
    "                    word_to_videos[word].append(video_id)\n",
    "    \n",
    "    print(f\"\\nâœ… Mapping created!\")\n",
    "    print(f\"   Total video instances: {len(video_to_word)}\")\n",
    "    print(f\"   Words found: {len(word_to_videos)}/{num_classes}\")\n",
    "    \n",
    "    # Show distribution\n",
    "    print(f\"\\n\udcca Videos per word (top 20):\")\n",
    "    sorted_words = sorted(word_to_videos.items(), key=lambda x: len(x[1]), reverse=True)\n",
    "    for i, (word, videos) in enumerate(sorted_words[:20], 1):\n",
    "        label = gloss_to_label[word]\n",
    "        print(f\"   {i:2d}. {word:20s} (Label {label:2d}) â†’ {len(videos):3d} videos\")\n",
    "    \n",
    "    # Check coverage\n",
    "    missing_words = set(gloss_to_label.keys()) - set(word_to_videos.keys())\n",
    "    if missing_words:\n",
    "        print(f\"\\nâš ï¸ Missing {len(missing_words)} words:\")\n",
    "        print(f\"   {sorted(list(missing_words))[:20]}\")\n",
    "    else:\n",
    "        print(f\"\\nâœ… All 100 words have video data!\")\n",
    "    \n",
    "    # Show stats\n",
    "    video_counts = [len(videos) for videos in word_to_videos.values()]\n",
    "    print(f\"\\nðŸ“Š Video distribution:\")\n",
    "    print(f\"   Min videos per word: {min(video_counts)}\")\n",
    "    print(f\"   Max videos per word: {max(video_counts)}\")\n",
    "    print(f\"   Mean videos per word: {np.mean(video_counts):.1f}\")\n",
    "    print(f\"   Median videos per word: {np.median(video_counts):.1f}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(f\"âœ… MAPPING COMPLETE! Ready to load dataset.\")\n",
    "print(f\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b596c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 6. LOAD AND PREPARE 100-WORD DATASET\n",
    "# ==========================================\n",
    "# Note: This creates the specific dataset for our target 100 words\n",
    "\n",
    "print(\"ðŸ“¦ Loading dataset for 100 words...\")\n",
    "\n",
    "X_data = []  # Landmarks\n",
    "y_data = []  # Labels\n",
    "video_ids_list = []  # Track which video\n",
    "\n",
    "# Load data for each word\n",
    "for word, videos in tqdm(word_to_videos.items(), desc=\"Loading words\"):\n",
    "    label = gloss_to_label[word]\n",
    "    \n",
    "    for video_id in videos:\n",
    "        # Construct file path\n",
    "        file_path = f\"{WLASL_DIR}/{video_id}.parquet\"\n",
    "        \n",
    "        if not os.path.exists(file_path):\n",
    "            continue\n",
    "        \n",
    "        # Load landmarks\n",
    "        df = load_parquet_landmarks(file_path)\n",
    "        if df is None:\n",
    "            continue\n",
    "        \n",
    "        # Convert to array\n",
    "        landmarks = parquet_to_array(df)\n",
    "        if landmarks is None:\n",
    "            continue\n",
    "        \n",
    "        # Resample to 30 frames\n",
    "        landmarks_resampled = resample_sequence(landmarks, TARGET_FRAMES)\n",
    "        \n",
    "        # Flatten to (30, 543*3) = (30, 1629)\n",
    "        landmarks_flat = landmarks_resampled.reshape(TARGET_FRAMES, -1)\n",
    "        \n",
    "        X_data.append(landmarks_flat)\n",
    "        y_data.append(label)\n",
    "        video_ids_list.append(video_id)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_data = np.array(X_data, dtype=np.float32)\n",
    "y_data = np.array(y_data, dtype=np.int32)\n",
    "\n",
    "print(f\"\\nâœ… Dataset loaded!\")\n",
    "print(f\"   Total samples: {len(X_data)}\")\n",
    "print(f\"   X shape: {X_data.shape}\")\n",
    "print(f\"   y shape: {y_data.shape}\")\n",
    "print(f\"   Unique classes: {len(np.unique(y_data))}\")\n",
    "\n",
    "# Check distribution\n",
    "unique, counts = np.unique(y_data, return_counts=True)\n",
    "print(f\"\\nðŸ“Š Samples per class:\")\n",
    "print(f\"   Min: {counts.min()}\")\n",
    "print(f\"   Max: {counts.max()}\")\n",
    "print(f\"   Mean: {counts.mean():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483575ac",
   "metadata": {},
   "source": [
    "# ðŸŽ¯ NEW STRATEGY: Pretrain + Fine-tune\n",
    "\n",
    "## Phase 1: Pretrain on ALL 2,000 Words\n",
    "- Use ALL WLASL data (~40,000 samples)\n",
    "- Train for 50 epochs\n",
    "- Save pretrained weights\n",
    "\n",
    "## Phase 2: Fine-tune on 100 Words\n",
    "- Load pretrained weights\n",
    "- Train only on your 100 words\n",
    "- Much better accuracy!\n",
    "\n",
    "## Why This is Better:\n",
    "âœ… More data = better feature learning\n",
    "âœ… Transfer learning = higher accuracy  \n",
    "âœ… Better generalization\n",
    "âœ… Still fast on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317d77de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 8. LOAD ALL 2,000 WORDS (PRETRAINING)\n",
    "# ==========================================\n",
    "\n",
    "print(\"ðŸ“¦ Loading ALL WLASL data for pretraining...\")\n",
    "\n",
    "# Create mapping for ALL words (not just 100)\n",
    "all_word_to_videos = {}\n",
    "all_video_to_word = {}\n",
    "\n",
    "print(\"ðŸ”— Creating mapping for ALL 2,000 words...\")\n",
    "for entry in tqdm(wlasl_full, desc=\"Processing all WLASL entries\"):\n",
    "    word = entry.get('gloss', None)\n",
    "    \n",
    "    if word:  # Include ALL words\n",
    "        instances = entry.get('instances', [])\n",
    "        \n",
    "        for instance in instances:\n",
    "            video_id = instance.get('video_id', None)\n",
    "            if video_id:\n",
    "                all_video_to_word[video_id] = word\n",
    "                if word not in all_word_to_videos:\n",
    "                    all_word_to_videos[word] = []\n",
    "                all_word_to_videos[word].append(video_id)\n",
    "\n",
    "print(f\"\\nâœ… Full mapping created!\")\n",
    "print(f\"   Total words: {len(all_word_to_videos)}\")\n",
    "print(f\"   Total videos: {len(all_video_to_word)}\")\n",
    "\n",
    "# Create label mapping for all words\n",
    "all_gloss_to_label = {word: i for i, word in enumerate(all_word_to_videos.keys())}\n",
    "all_label_to_gloss = {i: word for word, i in all_gloss_to_label.items()}\n",
    "\n",
    "print(f\"\\nðŸ“Š Full dataset stats:\")\n",
    "video_counts = [len(videos) for videos in all_word_to_videos.values()]\n",
    "print(f\"   Min videos per word: {min(video_counts)}\")\n",
    "print(f\"   Max videos per word: {max(video_counts)}\")\n",
    "print(f\"   Mean videos per word: {np.mean(video_counts):.1f}\")\n",
    "print(f\"   Total samples: {sum(video_counts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dbc39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 9. LOAD FULL DATASET (PRETRAINING)\n",
    "# ==========================================\n",
    "\n",
    "print(\"ðŸ“¦ Loading full dataset for pretraining...\")\n",
    "print(\"âš ï¸ This will take 10-20 minutes (loading ~40,000 samples)...\")\n",
    "\n",
    "X_full = []  # Landmarks\n",
    "y_full = []  # Labels\n",
    "\n",
    "# Load subset for faster pretraining (you can adjust)\n",
    "MAX_SAMPLES_PER_WORD = 50  # Limit to 50 samples per word for faster training\n",
    "loaded_samples = 0\n",
    "\n",
    "for word, videos in tqdm(all_word_to_videos.items(), desc=\"Loading all words\"):\n",
    "    label = all_gloss_to_label[word]\n",
    "    \n",
    "    # Limit samples per word\n",
    "    videos_to_load = videos[:MAX_SAMPLES_PER_WORD]\n",
    "    \n",
    "    for video_id in videos_to_load:\n",
    "        file_path = f\"{WLASL_DIR}/{video_id}.parquet\"\n",
    "        \n",
    "        if not os.path.exists(file_path):\n",
    "            continue\n",
    "        \n",
    "        # Load landmarks\n",
    "        df = load_parquet_landmarks(file_path)\n",
    "        if df is None:\n",
    "            continue\n",
    "        \n",
    "        # Convert to array\n",
    "        landmarks = parquet_to_array(df)\n",
    "        if landmarks is None:\n",
    "            continue\n",
    "        \n",
    "        # Resample to 30 frames\n",
    "        landmarks_resampled = resample_sequence(landmarks, TARGET_FRAMES)\n",
    "        landmarks_flat = landmarks_resampled.reshape(TARGET_FRAMES, -1)\n",
    "        \n",
    "        X_full.append(landmarks_flat)\n",
    "        y_full.append(label)\n",
    "        loaded_samples += 1\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_full = np.array(X_full, dtype=np.float32)\n",
    "y_full = np.array(y_full, dtype=np.int32)\n",
    "\n",
    "print(f\"\\nâœ… Full dataset loaded!\")\n",
    "print(f\"   Total samples: {len(X_full)}\")\n",
    "print(f\"   X shape: {X_full.shape}\")\n",
    "print(f\"   y shape: {y_full.shape}\")\n",
    "print(f\"   Unique classes: {len(np.unique(y_full))}\")\n",
    "\n",
    "# Split for pretraining\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_full, X_val_full, y_train_full, y_val_full = train_test_split(\n",
    "    X_full, y_full, test_size=0.2, random_state=42, stratify=y_full\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Pretrain split:\")\n",
    "print(f\"   Train: {len(X_train_full)} samples\")\n",
    "print(f\"   Val:   {len(X_val_full)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e612e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 10. BUILD PRETRAINING MODEL\n",
    "# ==========================================\n",
    "\n",
    "# Build LSTM model for pretraining (2,000 classes)\n",
    "def build_pretrain_model(input_shape, num_classes):\n",
    "    \"\"\"Build LSTM model for pretraining.\"\"\"\n",
    "    model = Sequential([\n",
    "        LSTM(128, return_sequences=True, activation='relu', input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        LSTM(256, return_sequences=True, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        LSTM(128, return_sequences=False, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build pretraining model\n",
    "INPUT_SHAPE = (TARGET_FRAMES, TOTAL_LANDMARKS * 3)  # (30, 1629)\n",
    "NUM_CLASSES_FULL = len(all_word_to_videos)  # ~2,000\n",
    "\n",
    "pretrain_model = build_pretrain_model(INPUT_SHAPE, NUM_CLASSES_FULL)\n",
    "\n",
    "# Compile\n",
    "pretrain_model.compile(\n",
    "    optimizer='Adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"âœ… Pretraining model built!\")\n",
    "print(f\"\\nðŸ“Š Model Info:\")\n",
    "print(f\"   Input shape: {INPUT_SHAPE}\")\n",
    "print(f\"   Output classes: {NUM_CLASSES_FULL}\")\n",
    "print(f\"   Total parameters: {pretrain_model.count_params():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da59385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 11. PRETRAIN MODEL\n",
    "# ==========================================\n",
    "\n",
    "# Callbacks\n",
    "pretrain_checkpoint = ModelCheckpoint(\n",
    "    '/kaggle/working/lstm_pretrained_2000.h5',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Pretrain\n",
    "print(\"ðŸš€ Starting pretraining on 2,000 words...\")\n",
    "print(f\"   Epochs: 50\")\n",
    "print(f\"   Batch size: 32\")\n",
    "print(f\"   Training samples: {len(X_train_full)}\")\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "\n",
    "pretrain_history = pretrain_model.fit(\n",
    "    X_train_full, y_train_full,\n",
    "    validation_data=(X_val_full, y_val_full),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[pretrain_checkpoint, reduce_lr, early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… Pretraining complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9541408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 12. FINE-TUNE ON 100 WORDS\n",
    "# ==========================================\n",
    "\n",
    "print(\"ðŸŽ¯ Fine-tuning on your 100 words...\")\n",
    "\n",
    "# Load pretrained model\n",
    "pretrained = tf.keras.models.load_model('/kaggle/working/lstm_pretrained_2000.h5')\n",
    "\n",
    "# Create fine-tuning model (100 classes)\n",
    "def build_finetune_model(pretrained_model, num_classes):\n",
    "    \"\"\"Create fine-tuning model from pretrained weights.\"\"\"\n",
    "    \n",
    "    # Get all layers except the final Dense layer\n",
    "    base_layers = pretrained_model.layers[:-1]\n",
    "    \n",
    "    # Create new model\n",
    "    inputs = pretrained_model.input\n",
    "    x = inputs\n",
    "    \n",
    "    # Add base layers (frozen initially)\n",
    "    for layer in base_layers:\n",
    "        x = layer(x)\n",
    "        layer.trainable = False  # Freeze initially\n",
    "    \n",
    "    # Add new classifier\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build fine-tuning model\n",
    "finetune_model = build_finetune_model(pretrained, num_classes)\n",
    "\n",
    "# Compile with smaller learning rate\n",
    "finetune_model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4),  # Smaller LR for fine-tuning\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"âœ… Fine-tuning model built!\")\n",
    "print(f\"   Base layers frozen: {sum(not layer.trainable for layer in finetune_model.layers)}\")\n",
    "print(f\"   Trainable layers: {sum(layer.trainable for layer in finetune_model.layers)}\")\n",
    "print(f\"   Total parameters: {finetune_model.count_params():,}\")\n",
    "\n",
    "# Load your 100-word data (reuse from earlier)\n",
    "print(\"\\nðŸ“¦ Loading 100-word dataset...\")\n",
    "# This will use the X_data, y_data from earlier cells\n",
    "# For now, let's assume we have them loaded\n",
    "\n",
    "# Train/val split for 100 words\n",
    "X_train_100, X_val_100, y_train_100, y_val_100 = train_test_split(\n",
    "    X_data, y_data, test_size=0.2, random_state=42, stratify=y_data\n",
    ")\n",
    "\n",
    "print(f\"   Train: {len(X_train_100)} samples\")\n",
    "print(f\"   Val:   {len(X_val_100)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b552969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 13. TRAIN FINE-TUNING MODEL\n",
    "# ==========================================\n",
    "\n",
    "# Callbacks for fine-tuning\n",
    "finetune_checkpoint = ModelCheckpoint(\n",
    "    '/kaggle/working/lstm_finetuned_100.h5',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fine-tune\n",
    "print(\"ðŸŽ¯ Starting fine-tuning on 100 words...\")\n",
    "print(f\"   Epochs: 30\")\n",
    "print(f\"   Batch size: 32\")\n",
    "\n",
    "finetune_history = finetune_model.fit(\n",
    "    X_train_100, y_train_100,\n",
    "    validation_data=(X_val_100, y_val_100),\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    callbacks=[finetune_checkpoint],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Fine-tuning complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f6cc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 14. EVALUATE & SAVE FINAL MODEL\n",
    "# ==========================================\n",
    "\n",
    "# Load best fine-tuned model\n",
    "best_model = tf.keras.models.load_model('/kaggle/working/lstm_finetuned_100.h5')\n",
    "\n",
    "# Evaluate on 100-word validation set\n",
    "print(\"ðŸ“Š Evaluating final model on 100 words...\")\n",
    "val_loss, val_acc = best_model.evaluate(X_val_100, y_val_100, verbose=0)\n",
    "\n",
    "print(f\"\\nâœ… Final Results:\")\n",
    "print(f\"   Val Loss:     {val_loss:.4f}\")\n",
    "print(f\"   Val Accuracy: {val_acc*100:.2f}%\")\n",
    "\n",
    "# Save final model and labels\n",
    "best_model.save('/kaggle/working/lstm_wlasl100_final.h5')\n",
    "print(\"   âœ… Saved: lstm_wlasl100_final.h5\")\n",
    "\n",
    "# Save label mapping\n",
    "final_mapping = {\n",
    "    'gloss_to_label': gloss_to_label,\n",
    "    'label_to_gloss': label_to_gloss,\n",
    "    'num_classes': num_classes,\n",
    "    'model_info': {\n",
    "        'input_shape': list(INPUT_SHAPE),\n",
    "        'target_frames': TARGET_FRAMES,\n",
    "        'total_landmarks': TOTAL_LANDMARKS,\n",
    "        'val_accuracy': float(val_acc),\n",
    "        'val_loss': float(val_loss),\n",
    "        'training_approach': 'pretrain_2000_finetune_100'\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('/kaggle/working/lstm_wlasl100_labels.json', 'w') as f:\n",
    "    json.dump(final_mapping, f, indent=2)\n",
    "print(\"   âœ… Saved: lstm_wlasl100_labels.json\")\n",
    "\n",
    "print(f\"\\nðŸ“¥ Download these files for local webcam inference:\")\n",
    "print(f\"   1. lstm_wlasl100_final.h5\")\n",
    "print(f\"   2. lstm_wlasl100_labels.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a5d763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 8. BUILD LSTM MODEL\n",
    "# ==========================================\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# Model architecture (based on Nicholas Renotte's approach)\n",
    "def build_lstm_model(input_shape, num_classes):\n",
    "    \"\"\"Build LSTM model for sign language recognition.\"\"\"\n",
    "    model = Sequential([\n",
    "        # Input: (30, 1629)\n",
    "        LSTM(64, return_sequences=True, activation='relu', input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        LSTM(128, return_sequences=True, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        LSTM(64, return_sequences=False, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build model\n",
    "INPUT_SHAPE = (TARGET_FRAMES, TOTAL_LANDMARKS * 3)  # (30, 1629)\n",
    "NUM_CLASSES = num_classes  # 100\n",
    "\n",
    "model = build_lstm_model(INPUT_SHAPE, NUM_CLASSES)\n",
    "\n",
    "# Compile\n",
    "model.compile(\n",
    "    optimizer='Adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"âœ… LSTM Model built!\")\n",
    "print(f\"\\nðŸ“Š Model Summary:\")\n",
    "model.summary()\n",
    "\n",
    "print(f\"\\nðŸ“Š Model Info:\")\n",
    "print(f\"   Input shape: {INPUT_SHAPE}\")\n",
    "print(f\"   Output classes: {NUM_CLASSES}\")\n",
    "print(f\"   Total parameters: {model.count_params():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0144e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8675ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4865de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af0e1db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289684d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 3. MATCH PARQUET FILES TO WORDS\n",
    "# ==========================================\n",
    "\n",
    "# Get all parquet files\n",
    "WLASL_DIR = \"/kaggle/input/wlasl2000-landmarks/wlasl_landmarks\"\n",
    "parquet_files = sorted(glob.glob(f\"{WLASL_DIR}/*.parquet\"))\n",
    "\n",
    "print(f\"\udcc1 Total parquet files: {len(parquet_files)}\")\n",
    "\n",
    "# We need to find which parquet files correspond to our 100 words\n",
    "# The WLASL dataset structure: each word has multiple video instances\n",
    "# We'll need to check if there's a mapping file or use the WLASL metadata\n",
    "\n",
    "# For now, let's check the nslt_2000.json structure more carefully\n",
    "WLASL_METADATA = \"/kaggle/input/wlasl-processed/nslt_2000.json\"\n",
    "\n",
    "with open(WLASL_METADATA, 'r') as f:\n",
    "    wlasl_meta = json.load(f)\n",
    "\n",
    "print(f\"\\nðŸ” Checking WLASL metadata structure...\")\n",
    "print(f\"   Type: {type(wlasl_meta)}\")\n",
    "\n",
    "# If it's a dict with video_id as keys\n",
    "if isinstance(wlasl_meta, dict):\n",
    "    # Get first entry\n",
    "    first_key = list(wlasl_meta.keys())[0]\n",
    "    first_value = wlasl_meta[first_key]\n",
    "    print(f\"\\n   Sample entry:\")\n",
    "    print(f\"   Key: {first_key}\")\n",
    "    print(f\"   Value: {first_value}\")\n",
    "    \n",
    "    # Check if 'action' field contains the word\n",
    "    if isinstance(first_value, dict) and 'action' in first_value:\n",
    "        print(f\"\\nâœ… Found 'action' field! This contains the word labels.\")\n",
    "        \n",
    "        # Create video_id â†’ word mapping\n",
    "        video_to_word = {}\n",
    "        word_to_videos = {}\n",
    "        \n",
    "        for video_id, data in wlasl_meta.items():\n",
    "            word = data.get('action', None)\n",
    "            if word and word in gloss_to_label:  # Only keep our 100 words\n",
    "                video_to_word[video_id] = word\n",
    "                if word not in word_to_videos:\n",
    "                    word_to_videos[word] = []\n",
    "                word_to_videos[word].append(video_id)\n",
    "        \n",
    "        print(f\"\\nâœ… Mapping created!\")\n",
    "        print(f\"   Videos matched to our 100 words: {len(video_to_word)}\")\n",
    "        print(f\"   Words found: {len(word_to_videos)}/{num_classes}\")\n",
    "        \n",
    "        # Show distribution\n",
    "        print(f\"\\nðŸ“Š Videos per word (sorted by count):\")\n",
    "        sorted_words = sorted(word_to_videos.items(), key=lambda x: len(x[1]), reverse=True)\n",
    "        for i, (word, videos) in enumerate(sorted_words[:20], 1):\n",
    "            label = gloss_to_label[word]\n",
    "            print(f\"   {i:2d}. {word:20s} (Label {label:2d}) â†’ {len(videos):3d} videos\")\n",
    "        \n",
    "        # Check coverage\n",
    "        missing_words = set(gloss_to_label.keys()) - set(word_to_videos.keys())\n",
    "        if missing_words:\n",
    "            print(f\"\\nâš ï¸ Missing {len(missing_words)} words from our 100-word list:\")\n",
    "            print(f\"   {sorted(list(missing_words))[:10]}...\")\n",
    "        else:\n",
    "            print(f\"\\nâœ… All 100 words have video data!\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(f\"âœ… DATA EXPLORATION COMPLETE!\")\n",
    "print(f\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
