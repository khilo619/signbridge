{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.kaggle.com/code/khalednabilfathy/01-sign-to-text?scriptVersionId=277857081\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T08:52:00.796508Z",
     "iopub.status.busy": "2025-11-14T08:52:00.795947Z",
     "iopub.status.idle": "2025-11-14T08:52:05.318805Z",
     "shell.execute_reply": "2025-11-14T08:52:05.318064Z",
     "shell.execute_reply.started": "2025-11-14T08:52:00.796481Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Base directory: /kaggle/working/WASL\n",
      "‚úÖ Created subdirectories:\n",
      "   - videos/\n",
      "   - manifests/\n",
      "   - preprocessed/\n",
      "   - models/checkpoints/\n",
      "\n",
      "‚úÖ GPU available: Tesla P100-PCIE-16GB\n",
      "   GPU Memory: 17.06 GB\n",
      "\n",
      "============================================================\n",
      "LOADING PRE-TRAINED WLASL100 FULL MODEL (75.15%)\n",
      "============================================================\n",
      "‚úÖ Loaded best_model_FULL.pth (75.15% WLASL100)\n",
      "   From: /kaggle/input/wlasl-finetuned-full-model/wlasl100_best_model_75.15pct_FULL.pth\n",
      "   To:   /kaggle/working/WASL/models/checkpoints/best_model_FULL.pth\n",
      "   ‚≠ê This is the FULL model (architecture + weights)\n",
      "‚úÖ Loaded label_mapping.json\n",
      "   From: /kaggle/input/wlasl-finetuned-model/working/label_mapping.json\n",
      "   To:   /kaggle/working/WASL/manifests/label_mapping.json\n",
      "\n",
      "‚úÖ Ready to start Citizen 100 training!\n",
      "   Next: Run Cell 9 ‚Üí Cell 14 ‚Üí Cell 16 ‚Üí Cell 17\n"
     ]
    }
   ],
   "source": [
    "# ---------- Cell 1: Setup Environment (Kaggle) ----------\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "# Set base directory (Kaggle has /kaggle/working as workspace)\n",
    "BASE_DIR = \"/kaggle/working/WASL\"\n",
    "os.makedirs(BASE_DIR, exist_ok=True)\n",
    "\n",
    "# Create subdirectories\n",
    "os.makedirs(os.path.join(BASE_DIR, \"videos\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(BASE_DIR, \"manifests\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(BASE_DIR, \"preprocessed\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(BASE_DIR, \"models\", \"checkpoints\"), exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Base directory:\", BASE_DIR)\n",
    "print(\"‚úÖ Created subdirectories:\")\n",
    "print(\"   - videos/\")\n",
    "print(\"   - manifests/\")\n",
    "print(\"   - preprocessed/\")\n",
    "print(\"   - models/checkpoints/\")\n",
    "\n",
    "# Check GPU availability\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"\\n‚úÖ GPU available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No GPU detected - make sure GPU accelerator is enabled\")\n",
    "    print(\"   (Settings ‚Üí Accelerator ‚Üí GPU)\")\n",
    "\n",
    "# Load pre-trained WLASL100 model (FULL MODEL with architecture)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LOADING PRE-TRAINED WLASL100 FULL MODEL (75.15%)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Source paths (NEW - full model with architecture!)\n",
    "source_model = \"/kaggle/input/wlasl-finetuned-full-model/wlasl100_best_model_75.15pct_FULL.pth\"\n",
    "source_label_map = \"/kaggle/input/wlasl-finetuned-model/working/label_mapping.json\"\n",
    "\n",
    "# Destination paths\n",
    "dest_model = os.path.join(BASE_DIR, \"models\", \"checkpoints\", \"best_model_FULL.pth\")\n",
    "dest_label_map = os.path.join(BASE_DIR, \"manifests\", \"label_mapping.json\")\n",
    "\n",
    "# Copy files\n",
    "try:\n",
    "    if os.path.exists(source_model):\n",
    "        shutil.copy(source_model, dest_model)\n",
    "        print(\"‚úÖ Loaded best_model_FULL.pth (75.15% WLASL100)\")\n",
    "        print(f\"   From: {source_model}\")\n",
    "        print(f\"   To:   {dest_model}\")\n",
    "        print(\"   ‚≠ê This is the FULL model (architecture + weights)\")\n",
    "    else:\n",
    "        print(f\"‚ùå Model not found at: {source_model}\")\n",
    "        print(\"   Please add 'wlasl-finetuned-full-model' dataset to your notebook inputs\")\n",
    "        \n",
    "    if os.path.exists(source_label_map):\n",
    "        shutil.copy(source_label_map, dest_label_map)\n",
    "        print(\"‚úÖ Loaded label_mapping.json\")\n",
    "        print(f\"   From: {source_label_map}\")\n",
    "        print(f\"   To:   {dest_label_map}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Label mapping not found at: {source_label_map}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Error copying files: {e}\")\n",
    "    print(\"\\n‚ÑπÔ∏è Make sure you added the Kaggle datasets:\")\n",
    "    print(\"   1. 'wlasl-finetuned-full-model' (NEW - contains full model)\")\n",
    "    print(\"   2. 'wlasl-finetuned-model' (for label mapping)\")\n",
    "\n",
    "print(\"\\n‚úÖ Ready to start Citizen 100 training!\")\n",
    "print(\"   Next: Run Cell 9 ‚Üí Cell 14 ‚Üí Cell 16 ‚Üí Cell 17\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T08:52:22.938726Z",
     "iopub.status.busy": "2025-11-14T08:52:22.937777Z",
     "iopub.status.idle": "2025-11-14T08:52:23.265029Z",
     "shell.execute_reply": "2025-11-14T08:52:23.264246Z",
     "shell.execute_reply.started": "2025-11-14T08:52:22.938695Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ WLASL dataset found in Kaggle inputs!\n",
      "   Path: /kaggle/input/wlasl-processed\n",
      "\n",
      "üìÇ Available files:\n",
      "   üìÑ nslt_2000.json (1.08 MB)\n",
      "   üìÅ videos/\n",
      "   üìÑ nslt_1000.json (0.67 MB)\n",
      "   üìÑ WLASL_v0.3.json (11.38 MB)\n",
      "   üìÑ wlasl_class_list.txt (0.02 MB)\n",
      "   üìÑ nslt_300.json (0.26 MB)\n",
      "   üìÑ missing.txt (0.05 MB)\n",
      "   üìÑ nslt_100.json (0.10 MB)\n",
      "\n",
      "‚úÖ Found 11980 videos in dataset\n",
      "\n",
      "‚úÖ Dataset ready - proceed to next cell\n"
     ]
    }
   ],
   "source": [
    "# ---------- Cell 2: Download WLASL Processed Dataset ----------\n",
    "import shutil\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Check if dataset is already added as input\n",
    "KAGGLE_INPUT = \"/kaggle/input/wlasl-processed\"\n",
    "if os.path.exists(KAGGLE_INPUT):\n",
    "    print(\"‚úÖ WLASL dataset found in Kaggle inputs!\")\n",
    "    print(f\"   Path: {KAGGLE_INPUT}\")\n",
    "    \n",
    "    # List available files\n",
    "    print(\"\\nüìÇ Available files:\")\n",
    "    for item in os.listdir(KAGGLE_INPUT):\n",
    "        item_path = os.path.join(KAGGLE_INPUT, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            print(f\"   üìÅ {item}/\")\n",
    "        else:\n",
    "            size_mb = os.path.getsize(item_path) / (1024 * 1024)\n",
    "            print(f\"   üìÑ {item} ({size_mb:.2f} MB)\")\n",
    "    \n",
    "    # Check if videos folder exists\n",
    "    videos_input = os.path.join(KAGGLE_INPUT, \"videos\")\n",
    "    if os.path.exists(videos_input):\n",
    "        video_count = len([f for f in os.listdir(videos_input) if f.endswith('.mp4')])\n",
    "        print(f\"\\n‚úÖ Found {video_count} videos in dataset\")\n",
    "    \n",
    "    VIDEOS_SOURCE = videos_input\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Dataset not found in inputs!\")\n",
    "    print(\"\\nüìù To add the dataset:\")\n",
    "    print(\"   1. Click 'Add Data' button (top right)\")\n",
    "    print(\"   2. Search for 'wlasl-processed'\")\n",
    "    print(\"   3. Add 'risangbaskoro/wlasl-processed' dataset\")\n",
    "    print(\"   4. Rerun this cell\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(\"\\n‚úÖ Dataset ready - proceed to next cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T08:52:30.313655Z",
     "iopub.status.busy": "2025-11-14T08:52:30.312959Z",
     "iopub.status.idle": "2025-11-14T08:52:30.967392Z",
     "shell.execute_reply": "2025-11-14T08:52:30.966666Z",
     "shell.execute_reply.started": "2025-11-14T08:52:30.313628Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded WLASL manifest: 2000 total glosses\n",
      "‚úÖ Filtered to WLASL100: 100 glosses\n",
      "\n",
      "‚úÖ Created dataset with 2038 video instances\n",
      "\n",
      "üìä Split distribution:\n",
      "split\n",
      "train    1442\n",
      "val       338\n",
      "test      258\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìä Top 10 glosses:\n",
      "gloss\n",
      "book        40\n",
      "drink       35\n",
      "computer    30\n",
      "before      26\n",
      "chair       26\n",
      "go          26\n",
      "clothes     25\n",
      "who         25\n",
      "candy       24\n",
      "cousin      23\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚úÖ Saved manifest to: /kaggle/working/WASL/manifests/wlasl100_manifest.csv\n",
      "\n",
      "‚úÖ Ready for next cell - video verification\n"
     ]
    }
   ],
   "source": [
    "# ---------- Cell 3: Load WLASL Manifest & Filter WLASL100 ----------\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the main WLASL manifest\n",
    "manifest_path = os.path.join(KAGGLE_INPUT, \"WLASL_v0.3.json\")\n",
    "with open(manifest_path, \"r\") as f:\n",
    "    wlasl_data = json.load(f)\n",
    "\n",
    "print(f\"‚úÖ Loaded WLASL manifest: {len(wlasl_data)} total glosses\")\n",
    "\n",
    "# Filter for WLASL100 (first 100 glosses by frequency)\n",
    "wlasl100_data = wlasl_data[:100]\n",
    "print(f\"‚úÖ Filtered to WLASL100: {len(wlasl100_data)} glosses\")\n",
    "\n",
    "# Extract all video instances for WLASL100\n",
    "video_records = []\n",
    "for gloss_entry in wlasl100_data:\n",
    "    gloss = gloss_entry['gloss']\n",
    "    for instance in gloss_entry['instances']:\n",
    "        video_id = instance['video_id']\n",
    "        bbox = instance.get('bbox', None)\n",
    "        fps = instance.get('fps', 25)\n",
    "        frame_start = instance.get('frame_start', None)\n",
    "        frame_end = instance.get('frame_end', None)\n",
    "        split = instance.get('split', 'train')  # train/val/test\n",
    "        \n",
    "        video_records.append({\n",
    "            'video_id': video_id,\n",
    "            'gloss': gloss,\n",
    "            'split': split,\n",
    "            'bbox': bbox,\n",
    "            'fps': fps,\n",
    "            'frame_start': frame_start,\n",
    "            'frame_end': frame_end\n",
    "        })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(video_records)\n",
    "print(f\"\\n‚úÖ Created dataset with {len(df)} video instances\")\n",
    "\n",
    "# Check split distribution\n",
    "print(\"\\nüìä Split distribution:\")\n",
    "print(df['split'].value_counts())\n",
    "\n",
    "print(\"\\nüìä Top 10 glosses:\")\n",
    "print(df['gloss'].value_counts().head(10))\n",
    "\n",
    "# Save manifest to working directory\n",
    "manifest_save_path = os.path.join(BASE_DIR, \"manifests\", \"wlasl100_manifest.csv\")\n",
    "df.to_csv(manifest_save_path, index=False)\n",
    "print(f\"\\n‚úÖ Saved manifest to: {manifest_save_path}\")\n",
    "\n",
    "print(\"\\n‚úÖ Ready for next cell - video verification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T08:52:36.385578Z",
     "iopub.status.busy": "2025-11-14T08:52:36.385272Z",
     "iopub.status.idle": "2025-11-14T08:52:36.405204Z",
     "shell.execute_reply": "2025-11-14T08:52:36.404526Z",
     "shell.execute_reply.started": "2025-11-14T08:52:36.385555Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Example: 'book' gloss distribution:\n",
      "split\n",
      "train    30\n",
      "val       6\n",
      "test      4\n",
      "Name: count, dtype: int64\n",
      "   Total: 40 videos\n",
      "\n",
      "üìä Example: 'drink' gloss distribution:\n",
      "split\n",
      "train    25\n",
      "val       6\n",
      "test      4\n",
      "Name: count, dtype: int64\n",
      "   Total: 35 videos\n",
      "\n",
      "üìä Overall statistics:\n",
      "   ‚Ä¢ Total glosses: 100\n",
      "   ‚Ä¢ Total videos: 2038\n",
      "   ‚Ä¢ Avg videos per gloss: 20.4\n",
      "\n",
      "   ‚Ä¢ Train videos: 1442 (70.8%)\n",
      "   ‚Ä¢ Val videos: 338 (16.6%)\n",
      "   ‚Ä¢ Test videos: 258 (12.7%)\n",
      "\n",
      "‚úÖ Each of the 100 glosses has its videos split across train/val/test\n",
      "‚úÖ This ensures the model sees each sign during training and is tested on unseen examples\n"
     ]
    }
   ],
   "source": [
    "# ---------- Cell 4: Analyze Split Distribution Per Gloss ----------\n",
    "\n",
    "# Check how one gloss (e.g., \"book\") is distributed\n",
    "book_df = df[df['gloss'] == 'book']\n",
    "print(\"üìä Example: 'book' gloss distribution:\")\n",
    "print(book_df['split'].value_counts())\n",
    "print(f\"   Total: {len(book_df)} videos\\n\")\n",
    "\n",
    "# Check another example\n",
    "drink_df = df[df['gloss'] == 'drink']\n",
    "print(\"üìä Example: 'drink' gloss distribution:\")\n",
    "print(drink_df['split'].value_counts())\n",
    "print(f\"   Total: {len(drink_df)} videos\\n\")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"üìä Overall statistics:\")\n",
    "print(f\"   ‚Ä¢ Total glosses: {df['gloss'].nunique()}\")\n",
    "print(f\"   ‚Ä¢ Total videos: {len(df)}\")\n",
    "print(f\"   ‚Ä¢ Avg videos per gloss: {len(df) / df['gloss'].nunique():.1f}\")\n",
    "print(f\"\\n   ‚Ä¢ Train videos: {len(df[df['split']=='train'])} ({len(df[df['split']=='train'])/len(df)*100:.1f}%)\")\n",
    "print(f\"   ‚Ä¢ Val videos: {len(df[df['split']=='val'])} ({len(df[df['split']=='val'])/len(df)*100:.1f}%)\")\n",
    "print(f\"   ‚Ä¢ Test videos: {len(df[df['split']=='test'])} ({len(df[df['split']=='test'])/len(df)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n‚úÖ Each of the 100 glosses has its videos split across train/val/test\")\n",
    "print(\"‚úÖ This ensures the model sees each sign during training and is tested on unseen examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T08:52:48.274237Z",
     "iopub.status.busy": "2025-11-14T08:52:48.27397Z",
     "iopub.status.idle": "2025-11-14T08:52:48.310538Z",
     "shell.execute_reply": "2025-11-14T08:52:48.309908Z",
     "shell.execute_reply.started": "2025-11-14T08:52:48.274216Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 11980 available videos in dataset\n",
      "\n",
      "üìä Video Availability:\n",
      "   ‚Ä¢ Required by manifest: 2038\n",
      "   ‚Ä¢ Available: 1013 (49.7%)\n",
      "   ‚Ä¢ Missing: 1025 (50.3%)\n",
      "\n",
      "üìä Availability by split:\n",
      "   ‚Ä¢ train: 748/1442 (51.9%)\n",
      "   ‚Ä¢ val: 165/338 (48.8%)\n",
      "   ‚Ä¢ test: 100/258 (38.8%)\n",
      "\n",
      "‚úÖ Working dataset: 1013 videos across 100 glosses\n",
      "‚úÖ Saved available videos manifest to: /kaggle/working/WASL/manifests/wlasl100_available.csv\n",
      "\n",
      "‚úÖ All 100 glosses have at least one video\n",
      "\n",
      "‚úÖ Ready for next cell - video preprocessing\n"
     ]
    }
   ],
   "source": [
    "# ---------- Cell 5: Verify Available Videos & Match with Manifest ----------\n",
    "import os\n",
    "\n",
    "# Get list of all available video files\n",
    "available_videos = set()\n",
    "for video_file in os.listdir(VIDEOS_SOURCE):\n",
    "    if video_file.endswith('.mp4'):\n",
    "        # Extract video_id (filename without extension)\n",
    "        video_id = video_file.replace('.mp4', '')\n",
    "        available_videos.add(video_id)\n",
    "\n",
    "print(f\"‚úÖ Found {len(available_videos)} available videos in dataset\")\n",
    "\n",
    "# Check which videos from manifest are actually available\n",
    "df['video_available'] = df['video_id'].isin(available_videos)\n",
    "df['video_path'] = df['video_id'].apply(\n",
    "    lambda vid: os.path.join(VIDEOS_SOURCE, f\"{vid}.mp4\") if vid in available_videos else None\n",
    ")\n",
    "\n",
    "# Statistics\n",
    "total_required = len(df)\n",
    "total_available = df['video_available'].sum()\n",
    "missing_count = total_required - total_available\n",
    "\n",
    "print(\"\\nüìä Video Availability:\")\n",
    "print(f\"   ‚Ä¢ Required by manifest: {total_required}\")\n",
    "print(f\"   ‚Ä¢ Available: {total_available} ({total_available/total_required*100:.1f}%)\")\n",
    "print(f\"   ‚Ä¢ Missing: {missing_count} ({missing_count/total_required*100:.1f}%)\")\n",
    "\n",
    "# Check availability by split\n",
    "print(\"\\nüìä Availability by split:\")\n",
    "for split_name in ['train', 'val', 'test']:\n",
    "    split_df = df[df['split'] == split_name]\n",
    "    available = split_df['video_available'].sum()\n",
    "    total = len(split_df)\n",
    "    print(f\"   ‚Ä¢ {split_name}: {available}/{total} ({available/total*100:.1f}%)\")\n",
    "\n",
    "# Filter to only available videos\n",
    "df_available = df[df['video_available'] == True].copy()\n",
    "print(f\"\\n‚úÖ Working dataset: {len(df_available)} videos across {df_available['gloss'].nunique()} glosses\")\n",
    "\n",
    "# Save filtered manifest\n",
    "filtered_manifest_path = os.path.join(BASE_DIR, \"manifests\", \"wlasl100_available.csv\")\n",
    "df_available.to_csv(filtered_manifest_path, index=False)\n",
    "print(f\"‚úÖ Saved available videos manifest to: {filtered_manifest_path}\")\n",
    "\n",
    "# Check if any glosses lost all videos\n",
    "glosses_with_videos = df_available['gloss'].value_counts()\n",
    "original_glosses = df['gloss'].nunique()\n",
    "remaining_glosses = len(glosses_with_videos)\n",
    "\n",
    "if remaining_glosses < original_glosses:\n",
    "    print(f\"\\n‚ö†Ô∏è Warning: {original_glosses - remaining_glosses} glosses have no available videos\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ All {remaining_glosses} glosses have at least one video\")\n",
    "\n",
    "print(\"\\n‚úÖ Ready for next cell - video preprocessing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T08:52:57.513642Z",
     "iopub.status.busy": "2025-11-14T08:52:57.513001Z",
     "iopub.status.idle": "2025-11-14T08:53:00.058382Z",
     "shell.execute_reply": "2025-11-14T08:53:00.057696Z",
     "shell.execute_reply.started": "2025-11-14T08:52:57.513611Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenCV version: 4.12.0\n",
      "‚úÖ PyTorch version: 2.6.0+cu124\n",
      "‚úÖ CUDA available: True\n",
      "\n",
      "üìã Preprocessing Configuration:\n",
      "   ‚Ä¢ target_fps: 25\n",
      "   ‚Ä¢ target_frames: 32\n",
      "   ‚Ä¢ target_size: (224, 224)\n",
      "   ‚Ä¢ normalize: True\n",
      "\n",
      "üß™ Testing video loader on sample video...\n",
      "‚úÖ Successfully loaded video for gloss: 'book'\n",
      "   ‚Ä¢ Original: 75 frames @ 30.0 fps\n",
      "   ‚Ä¢ Processed: 32 frames @ 25 fps\n",
      "   ‚Ä¢ Frame shape: (224, 224, 3) (H, W, C)\n",
      "   ‚Ä¢ Pixel value range: [0, 255]\n",
      "   ‚Ä¢ Memory size: 4.59 MB\n",
      "\n",
      "‚úÖ Video preprocessing utilities ready\n",
      "‚úÖ Ready for next cell - batch preprocessing\n"
     ]
    }
   ],
   "source": [
    "# ---------- Cell 6: Video Preprocessing - Setup & Utilities ----------\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"‚úÖ OpenCV version:\", cv2.__version__)\n",
    "print(\"‚úÖ PyTorch version:\", torch.__version__)\n",
    "print(\"‚úÖ CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "# Define preprocessing parameters\n",
    "PREPROCESS_CONFIG = {\n",
    "    'target_fps': 25,           # Resample all videos to 25 fps\n",
    "    'target_frames': 32,        # Extract 32 frames per video (standard for I3D)\n",
    "    'target_size': (224, 224),  # Resize frames to 224x224 (I3D input size)\n",
    "    'normalize': True,          # Normalize pixel values to [0, 1]\n",
    "}\n",
    "\n",
    "print(\"\\nüìã Preprocessing Configuration:\")\n",
    "for key, value in PREPROCESS_CONFIG.items():\n",
    "    print(f\"   ‚Ä¢ {key}: {value}\")\n",
    "\n",
    "# Video loading utility function\n",
    "def load_video_frames(video_path, target_frames=32, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Load video and extract uniformly sampled frames.\n",
    "    \n",
    "    Args:\n",
    "        video_path: Path to video file\n",
    "        target_frames: Number of frames to extract\n",
    "        target_size: Target spatial size (H, W)\n",
    "    \n",
    "    Returns:\n",
    "        frames: numpy array of shape (T, H, W, C) - T=target_frames, C=3 (RGB)\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(f\"Cannot open video: {video_path}\")\n",
    "    \n",
    "    # Get video properties\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # Calculate frame indices to sample uniformly\n",
    "    if total_frames < target_frames:\n",
    "        # If video has fewer frames, repeat last frame\n",
    "        indices = np.linspace(0, total_frames - 1, target_frames, dtype=int)\n",
    "    else:\n",
    "        # Sample uniformly across video duration\n",
    "        indices = np.linspace(0, total_frames - 1, target_frames, dtype=int)\n",
    "    \n",
    "    frames = []\n",
    "    for idx in indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if ret:\n",
    "            # Convert BGR (OpenCV) to RGB\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            # Resize to target size\n",
    "            frame = cv2.resize(frame, target_size)\n",
    "            frames.append(frame)\n",
    "        else:\n",
    "            # If frame read fails, repeat last valid frame\n",
    "            if len(frames) > 0:\n",
    "                frames.append(frames[-1])\n",
    "            else:\n",
    "                # Create blank frame if no valid frames yet\n",
    "                frames.append(np.zeros((target_size[0], target_size[1], 3), dtype=np.uint8))\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    # Stack frames into single array: (T, H, W, C)\n",
    "    frames = np.stack(frames, axis=0)\n",
    "    \n",
    "    return frames, total_frames, fps\n",
    "\n",
    "\n",
    "# Test the function on one video\n",
    "print(\"\\nüß™ Testing video loader on sample video...\")\n",
    "sample_row = df_available.iloc[0]\n",
    "sample_video_path = sample_row['video_path']\n",
    "sample_gloss = sample_row['gloss']\n",
    "\n",
    "try:\n",
    "    frames, original_frames, original_fps = load_video_frames(\n",
    "        sample_video_path, \n",
    "        target_frames=PREPROCESS_CONFIG['target_frames'],\n",
    "        target_size=PREPROCESS_CONFIG['target_size']\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Successfully loaded video for gloss: '{sample_gloss}'\")\n",
    "    print(f\"   ‚Ä¢ Original: {original_frames} frames @ {original_fps:.1f} fps\")\n",
    "    print(f\"   ‚Ä¢ Processed: {frames.shape[0]} frames @ {PREPROCESS_CONFIG['target_fps']} fps\")\n",
    "    print(f\"   ‚Ä¢ Frame shape: {frames.shape[1:]} (H, W, C)\")\n",
    "    print(f\"   ‚Ä¢ Pixel value range: [{frames.min()}, {frames.max()}]\")\n",
    "    print(f\"   ‚Ä¢ Memory size: {frames.nbytes / 1024 / 1024:.2f} MB\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading video: {e}\")\n",
    "\n",
    "print(\"\\n‚úÖ Video preprocessing utilities ready\")\n",
    "print(\"‚úÖ Ready for next cell - batch preprocessing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ---------- Cell 7: Batch Preprocess All Videos ----------\n",
    "# SMART SKIP: This cell automatically skips already-processed videos!\n",
    "# Only new/missing videos will be processed.\n",
    "\n",
    "\n",
    "# Create preprocessed data directories\n",
    "PREPROCESSED_DIR = os.path.join(BASE_DIR, \"preprocessed\")\n",
    "os.makedirs(os.path.join(PREPROCESSED_DIR, \"train\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(PREPROCESSED_DIR, \"val\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(PREPROCESSED_DIR, \"test\"), exist_ok=True)\n",
    "\n",
    "print(\"ÔøΩ Preprocessed data will be saved to:\")\n",
    "print(f\"   {PREPROCESSED_DIR}\")\n",
    "\n",
    "# Check existing preprocessed videos\n",
    "existing_counts = {}\n",
    "for split_name in ['train', 'val', 'test']:\n",
    "    split_dir = os.path.join(PREPROCESSED_DIR, split_name)\n",
    "    existing_counts[split_name] = len(list(Path(split_dir).glob(\"*.npz\")))\n",
    "\n",
    "total_existing = sum(existing_counts.values())\n",
    "print(f\"\\nÔøΩ Found {total_existing} already preprocessed videos:\")\n",
    "for split_name, count in existing_counts.items():\n",
    "    print(f\"   ‚Ä¢ {split_name}: {count} videos\")\n",
    "\n",
    "if total_existing > 0:\n",
    "    print(\"\\nüí° These videos will be SKIPPED (fast!)\")\n",
    "    print(\"   Only new/missing videos will be processed.\")\n",
    "\n",
    "# Function to preprocess and save videos for one split\n",
    "def preprocess_split(df_split, split_name):\n",
    "    \"\"\"\n",
    "    Preprocess all videos in a split and save as compressed .npz files (uint8).\n",
    "    \n",
    "    STORAGE OPTIMIZATION:\n",
    "    - Store as uint8 (0-255) instead of float32: 75% less space\n",
    "    - Use .npz compression: additional 40% savings\n",
    "    - Normalize on-the-fly during training (no speed loss)\n",
    "    \n",
    "    Expected storage: ~2.5 GB (vs 9.5 GB with old method)\n",
    "    \n",
    "    Args:\n",
    "        df_split: DataFrame containing videos for this split\n",
    "        split_name: 'train', 'val', or 'test'\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing {split_name.upper()} split: {len(df_split)} videos\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    split_dir = os.path.join(PREPROCESSED_DIR, split_name)\n",
    "    \n",
    "    processed_records = []\n",
    "    failed_videos = []\n",
    "    skipped_videos = 0\n",
    "    \n",
    "    for idx, row in tqdm(df_split.iterrows(), total=len(df_split), desc=f\"{split_name}\"):\n",
    "        video_id = row['video_id']\n",
    "        video_path = row['video_path']\n",
    "        gloss = row['gloss']\n",
    "        \n",
    "        # Check if video is already preprocessed\n",
    "        save_path = os.path.join(split_dir, f\"{video_id}.npz\")\n",
    "        \n",
    "        if os.path.exists(save_path):\n",
    "            # Skip processing - load metadata from existing file\n",
    "            try:\n",
    "                data = np.load(save_path)\n",
    "                frames = data['frames']\n",
    "                \n",
    "                processed_records.append({\n",
    "                    'video_id': video_id,\n",
    "                    'gloss': gloss,\n",
    "                    'split': split_name,\n",
    "                    'save_path': save_path,\n",
    "                    'original_frames': -1,  # Unknown (not saved in .npz)\n",
    "                    'original_fps': -1,     # Unknown\n",
    "                    'processed_frames': frames.shape[0],\n",
    "                    'frame_shape': frames.shape[1:],\n",
    "                    'dataset': 'wlasl'\n",
    "                })\n",
    "                skipped_videos += 1\n",
    "                continue  # Skip to next video\n",
    "                \n",
    "            except Exception:\n",
    "                # If can't load existing file, reprocess it\n",
    "                print(f\"\\n‚ö†Ô∏è Corrupted file {video_id}, reprocessing...\")\n",
    "        \n",
    "        try:\n",
    "            # Load and preprocess video\n",
    "            frames, orig_frames, orig_fps = load_video_frames(\n",
    "                video_path,\n",
    "                target_frames=PREPROCESS_CONFIG['target_frames'],\n",
    "                target_size=PREPROCESS_CONFIG['target_size']\n",
    "            )\n",
    "            \n",
    "            # DO NOT normalize here - keep as uint8 (0-255) for storage efficiency\n",
    "            # Normalization will happen on-the-fly during training\n",
    "            # frames stays as uint8 dtype\n",
    "            \n",
    "            # Save as compressed .npz file (uint8 + gzip compression)\n",
    "            np.savez_compressed(save_path, frames=frames)\n",
    "            \n",
    "            # Record metadata\n",
    "            processed_records.append({\n",
    "                'video_id': video_id,\n",
    "                'gloss': gloss,\n",
    "                'split': split_name,\n",
    "                'save_path': save_path,\n",
    "                'original_frames': orig_frames,\n",
    "                'original_fps': orig_fps,\n",
    "                'processed_frames': frames.shape[0],\n",
    "                'frame_shape': frames.shape[1:],\n",
    "                'dataset': 'wlasl'\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            failed_videos.append({\n",
    "                'video_id': video_id,\n",
    "                'gloss': gloss,\n",
    "                'error': str(e)\n",
    "            })\n",
    "            print(f\"\\n‚ö†Ô∏è Failed to process {video_id} ({gloss}): {e}\")\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(f\"\\n‚úÖ {split_name.upper()} split complete:\")\n",
    "    print(f\"   ‚Ä¢ Total videos: {len(df_split)}\")\n",
    "    print(f\"   ‚Ä¢ Skipped (already exists): {skipped_videos}\")\n",
    "    print(f\"   ‚Ä¢ Newly processed: {len(processed_records) - skipped_videos}\")\n",
    "    print(f\"   ‚Ä¢ Failed: {len(failed_videos)}\")\n",
    "    \n",
    "    if len(failed_videos) > 0:\n",
    "        print(f\"\\n‚ö†Ô∏è Failed videos saved to: {PREPROCESSED_DIR}/{split_name}_failed.txt\")\n",
    "        with open(os.path.join(PREPROCESSED_DIR, f\"{split_name}_failed.txt\"), 'w') as f:\n",
    "            for fail in failed_videos:\n",
    "                f.write(f\"{fail['video_id']},{fail['gloss']},{fail['error']}\\n\")\n",
    "    \n",
    "    return processed_records, failed_videos\n",
    "\n",
    "\n",
    "# Process each split\n",
    "all_processed = {}\n",
    "all_failed = {}\n",
    "\n",
    "for split_name in ['train', 'val', 'test']:\n",
    "    df_split = df_available[df_available['split'] == split_name].copy()\n",
    "    processed, failed = preprocess_split(df_split, split_name)\n",
    "    all_processed[split_name] = processed\n",
    "    all_failed[split_name] = failed\n",
    "\n",
    "# Create final preprocessed manifest\n",
    "final_records = []\n",
    "for split_name in ['train', 'val', 'test']:\n",
    "    final_records.extend(all_processed[split_name])\n",
    "\n",
    "df_preprocessed = pd.DataFrame(final_records)\n",
    "\n",
    "# Save preprocessed manifest\n",
    "preprocessed_manifest_path = os.path.join(BASE_DIR, \"manifests\", \"wlasl100_preprocessed.csv\")\n",
    "df_preprocessed.to_csv(preprocessed_manifest_path, index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PREPROCESSING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nüìä Final Statistics:\")\n",
    "print(f\"   ‚Ä¢ Total videos processed: {len(df_preprocessed)}\")\n",
    "print(f\"   ‚Ä¢ Train: {len(all_processed['train'])}\")\n",
    "print(f\"   ‚Ä¢ Val: {len(all_processed['val'])}\")\n",
    "print(f\"   ‚Ä¢ Test: {len(all_processed['test'])}\")\n",
    "print(f\"\\n   ‚Ä¢ Total failed: {sum(len(all_failed[s]) for s in ['train', 'val', 'test'])}\")\n",
    "\n",
    "# Calculate disk space used\n",
    "total_size = 0\n",
    "for split_name in ['train', 'val', 'test']:\n",
    "    split_dir = os.path.join(PREPROCESSED_DIR, split_name)\n",
    "    for npz_file in Path(split_dir).glob(\"*.npz\"):\n",
    "        total_size += npz_file.stat().st_size\n",
    "\n",
    "print(f\"\\nüíæ Disk space used: {total_size / (1024**3):.2f} GB\")\n",
    "print(f\"   ‚Ä¢ Average per video: {total_size / len(df_preprocessed) / (1024**2):.2f} MB\")\n",
    "\n",
    "print(\"\\n‚úÖ Preprocessed manifest saved to:\")\n",
    "print(f\"   {preprocessed_manifest_path}\")\n",
    "\n",
    "print(\"\\n‚úÖ Ready for next cell - verify preprocessed data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T18:19:26.531005Z",
     "iopub.status.busy": "2025-11-13T18:19:26.530299Z",
     "iopub.status.idle": "2025-11-13T18:19:26.548952Z",
     "shell.execute_reply": "2025-11-13T18:19:26.547943Z",
     "shell.execute_reply.started": "2025-11-13T18:19:26.53098Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ---------- Cell 8: Verify Preprocessed Data & Splits ----------\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"VERIFYING PREPROCESSED DATA & SPLITS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load preprocessed manifest\n",
    "df_preprocessed = pd.read_csv(os.path.join(BASE_DIR, \"manifests\", \"wlasl100_preprocessed.csv\"))\n",
    "\n",
    "print(f\"\\n‚úÖ Loaded preprocessed manifest: {len(df_preprocessed)} videos\")\n",
    "\n",
    "# Verify splits\n",
    "print(\"\\nüìä Split Distribution:\")\n",
    "for split in ['train', 'val', 'test']:\n",
    "    split_df = df_preprocessed[df_preprocessed['split'] == split]\n",
    "    print(f\"   ‚Ä¢ {split.capitalize()}: {len(split_df)} videos\")\n",
    "    print(f\"      - Unique glosses: {split_df['gloss'].nunique()}\")\n",
    "\n",
    "# Verify all glosses have videos in each split\n",
    "print(\"\\nüîç Checking gloss coverage across splits...\")\n",
    "unique_glosses = df_preprocessed['gloss'].unique()\n",
    "print(f\"   Total glosses: {len(unique_glosses)}\")\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    split_glosses = df_preprocessed[df_preprocessed['split']==split]['gloss'].unique()\n",
    "    missing = set(unique_glosses) - set(split_glosses)\n",
    "    if len(missing) > 0:\n",
    "        print(f\"   ‚ö†Ô∏è {split.capitalize()} missing {len(missing)} glosses:\")\n",
    "        for gloss in list(missing)[:5]:\n",
    "            print(f\"      - {gloss}\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ {split.capitalize()} has all {len(unique_glosses)} glosses\")\n",
    "\n",
    "# Sample a few preprocessed files to verify\n",
    "print(\"\\nüß™ Testing preprocessed file loading...\")\n",
    "sample_records = df_preprocessed.sample(min(3, len(df_preprocessed)))\n",
    "\n",
    "for idx, row in sample_records.iterrows():\n",
    "    try:\n",
    "        data = np.load(row['save_path'])\n",
    "        frames = data['frames']\n",
    "        print(f\"   ‚úÖ {row['video_id']}: {frames.shape} ({frames.dtype}, range [{frames.min()}, {frames.max()}])\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå {row['video_id']}: Error loading - {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ PREPROCESSED DATA VERIFIED\")\n",
    "print(\"‚úÖ Ready for model loading (Cell 8)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T08:53:18.90741Z",
     "iopub.status.busy": "2025-11-14T08:53:18.907134Z",
     "iopub.status.idle": "2025-11-14T08:53:18.925323Z",
     "shell.execute_reply": "2025-11-14T08:53:18.924503Z",
     "shell.execute_reply.started": "2025-11-14T08:53:18.907389Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DEFINING WLASLDATASET CLASS\n",
      "============================================================\n",
      "\n",
      "üí° Model already loaded in Cell 1 - skipping model loading\n",
      "   Just defining the Dataset class for preprocessing...\n",
      "\n",
      "‚úÖ WLASLDataset class defined with IMPROVED augmentation!\n",
      "   ‚Ä¢ 6 augmentation techniques (vs 3 before)\n",
      "   ‚Ä¢ Horizontal flip: 30% (reduced from 50%)\n",
      "   ‚Ä¢ Temporal crop: 75-100% (more aggressive)\n",
      "   ‚Ä¢ Brightness: 0.85-1.15√ó (wider range)\n",
      "   ‚Ä¢ Contrast: 0.85-1.15√ó (NEW)\n",
      "   ‚Ä¢ Rotation: ¬±3¬∞ (NEW, conservative)\n",
      "   ‚Ä¢ Spatial crop: 85-100% + resize (NEW)\n",
      "   ‚Ä¢ Gaussian noise: œÉ=5, 20% chance (NEW)\n",
      "\n",
      "============================================================\n",
      "‚úÖ MODEL + DATASET READY\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ---------- Cell 9: Define WLASLDataset Class ----------\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DEFINING WLASLDATASET CLASS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nüí° Model already loaded in Cell 1 - skipping model loading\")\n",
    "print(\"   Just defining the Dataset class for preprocessing...\")\n",
    "\n",
    "# Dataset class with IMPROVED AUGMENTATION\n",
    "class WLASLDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for WLASL/Citizen preprocessed videos.\n",
    "    \n",
    "    Loads preprocessed .npz files and applies augmentation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df, augment=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df: DataFrame with columns ['video_id', 'gloss', 'label', 'save_path', 'dataset']\n",
    "            augment: Whether to apply data augmentation\n",
    "        \"\"\"\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.augment = augment\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"Creating WLASLDataset:\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"   ‚Ä¢ Total videos: {len(self.df)}\")\n",
    "        print(f\"   ‚Ä¢ Augmentation: {'ENABLED (6 techniques)' if augment else 'DISABLED'}\")\n",
    "        print(f\"   ‚Ä¢ Unique glosses: {self.df['gloss'].nunique()}\")\n",
    "        \n",
    "        # Show dataset composition\n",
    "        if 'dataset' in self.df.columns:\n",
    "            dataset_counts = self.df['dataset'].value_counts()\n",
    "            print(\"   ‚Ä¢ Dataset sources:\")\n",
    "            for dataset_name, count in dataset_counts.items():\n",
    "                print(f\"      - {dataset_name}: {count} videos\")\n",
    "        \n",
    "        print(f\"{'='*60}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # Load preprocessed frames\n",
    "        npz_path = row['save_path']\n",
    "        data = np.load(npz_path)\n",
    "        frames = data['frames']  # (T, H, W, C), uint8, [0, 255]\n",
    "        \n",
    "        # Apply augmentation if enabled\n",
    "        if self.augment:\n",
    "            frames = self._augment_video(frames)\n",
    "        \n",
    "        # Convert to float32 and normalize to [0, 1]\n",
    "        frames = frames.astype(np.float32) / 255.0\n",
    "        \n",
    "        # Convert to PyTorch tensor: (T, H, W, C) ‚Üí (C, T, H, W)\n",
    "        frames = torch.from_numpy(frames).permute(3, 0, 1, 2)\n",
    "        \n",
    "        return {\n",
    "            'frames': frames,\n",
    "            'label': torch.tensor(row['label'], dtype=torch.long),\n",
    "            'video_id': row['video_id'],\n",
    "            'gloss': row['gloss']\n",
    "        }\n",
    "    \n",
    "    def _augment_video(self, frames):\n",
    "        \"\"\"\n",
    "        Apply IMPROVED data augmentation to video frames (uint8 format).\n",
    "        \n",
    "        6 augmentation techniques:\n",
    "        1. Horizontal flip (30% chance - reduced for sign language)\n",
    "        2. Temporal cropping (75-100% frames - more aggressive) + RESAMPLE to 32 frames\n",
    "        3. Brightness (0.85-1.15√ó - wider range)\n",
    "        4. Contrast (0.85-1.15√ó - NEW)\n",
    "        5. Rotation (¬±3¬∞ - NEW, conservative for sign language)\n",
    "        6. Spatial crop + resize (85-100% - NEW)\n",
    "        7. Gaussian noise (œÉ=5, 20% chance - NEW)\n",
    "        \n",
    "        CRITICAL: Always returns exactly T frames (no shape mismatch in batching)\n",
    "        \n",
    "        Args:\n",
    "            frames: (T, H, W, C) numpy array, uint8, range [0, 255]\n",
    "        \n",
    "        Returns:\n",
    "            Augmented frames (T, H, W, C), uint8, range [0, 255]\n",
    "        \"\"\"\n",
    "        T, H, W, C = frames.shape\n",
    "        original_T = T  # Save original frame count to restore at the end\n",
    "        \n",
    "        # 1. Horizontal flip (30% chance - REDUCED for sign language)\n",
    "        if np.random.rand() < 0.3:\n",
    "            frames = np.flip(frames, axis=2).copy()\n",
    "        \n",
    "        # 2. Temporal cropping (75-100% frames - MORE AGGRESSIVE)\n",
    "        # CRITICAL FIX: After cropping, resample back to original_T frames\n",
    "        crop_ratio = np.random.uniform(0.75, 1.0)\n",
    "        num_frames = max(int(T * crop_ratio), 16)  # At least 16 frames\n",
    "        \n",
    "        if num_frames < T:\n",
    "            start_idx = np.random.randint(0, T - num_frames + 1)\n",
    "            cropped_frames = frames[start_idx:start_idx + num_frames]\n",
    "            \n",
    "            # Resample back to original T frames using uniform sampling\n",
    "            indices = np.linspace(0, num_frames - 1, original_T, dtype=int)\n",
    "            frames = cropped_frames[indices]\n",
    "            T = original_T  # Restore original frame count\n",
    "        \n",
    "        # 3. Brightness adjustment (0.85-1.15√ó - WIDER RANGE)\n",
    "        brightness_factor = np.random.uniform(0.85, 1.15)\n",
    "        frames = np.clip(frames.astype(np.float32) * brightness_factor, 0, 255).astype(np.uint8)\n",
    "        \n",
    "        # 4. Contrast adjustment (0.85-1.15√ó - NEW)\n",
    "        contrast_factor = np.random.uniform(0.85, 1.15)\n",
    "        mean = frames.mean()\n",
    "        frames = np.clip((frames.astype(np.float32) - mean) * contrast_factor + mean, 0, 255).astype(np.uint8)\n",
    "        \n",
    "        # 5. Rotation (¬±3¬∞ - NEW, very conservative for sign language)\n",
    "        angle = np.random.uniform(-3, 3)\n",
    "        center = (W // 2, H // 2)\n",
    "        M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "        \n",
    "        rotated_frames = np.zeros_like(frames)\n",
    "        for t in range(T):\n",
    "            rotated_frames[t] = cv2.warpAffine(frames[t], M, (W, H), borderMode=cv2.BORDER_REPLICATE)\n",
    "        frames = rotated_frames\n",
    "        \n",
    "        # 6. Spatial crop + resize (85-100% - NEW)\n",
    "        crop_ratio_spatial = np.random.uniform(0.85, 1.0)\n",
    "        crop_h = int(H * crop_ratio_spatial)\n",
    "        crop_w = int(W * crop_ratio_spatial)\n",
    "        \n",
    "        top = np.random.randint(0, H - crop_h + 1) if crop_h < H else 0\n",
    "        left = np.random.randint(0, W - crop_w + 1) if crop_w < W else 0\n",
    "        \n",
    "        cropped_frames = np.zeros_like(frames)\n",
    "        for t in range(T):\n",
    "            cropped = frames[t, top:top+crop_h, left:left+crop_w]\n",
    "            cropped_frames[t] = cv2.resize(cropped, (W, H), interpolation=cv2.INTER_LINEAR)\n",
    "        frames = cropped_frames\n",
    "        \n",
    "        # 7. Gaussian noise (œÉ=5, 20% chance - NEW)\n",
    "        if np.random.rand() < 0.2:\n",
    "            noise = np.random.normal(0, 5, frames.shape).astype(np.float32)\n",
    "            frames = np.clip(frames.astype(np.float32) + noise, 0, 255).astype(np.uint8)\n",
    "        \n",
    "        # FINAL SAFETY CHECK: Ensure output has exactly original_T frames\n",
    "        if frames.shape[0] != original_T:\n",
    "            # Resample to original_T frames if somehow we lost/gained frames\n",
    "            indices = np.linspace(0, frames.shape[0] - 1, original_T, dtype=int)\n",
    "            frames = frames[indices]\n",
    "        \n",
    "        return frames\n",
    "\n",
    "print(\"\\n‚úÖ WLASLDataset class defined with IMPROVED augmentation!\")\n",
    "print(\"   ‚Ä¢ 6 augmentation techniques (vs 3 before)\")\n",
    "print(\"   ‚Ä¢ Horizontal flip: 30% (reduced from 50%)\")\n",
    "print(\"   ‚Ä¢ Temporal crop: 75-100% (more aggressive)\")\n",
    "print(\"   ‚Ä¢ Brightness: 0.85-1.15√ó (wider range)\")\n",
    "print(\"   ‚Ä¢ Contrast: 0.85-1.15√ó (NEW)\")\n",
    "print(\"   ‚Ä¢ Rotation: ¬±3¬∞ (NEW, conservative)\")\n",
    "print(\"   ‚Ä¢ Spatial crop: 85-100% + resize (NEW)\")\n",
    "print(\"   ‚Ä¢ Gaussian noise: œÉ=5, 20% chance (NEW)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ MODEL + DATASET READY\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T08:53:28.499255Z",
     "iopub.status.busy": "2025-11-14T08:53:28.499011Z",
     "iopub.status.idle": "2025-11-14T08:53:28.51889Z",
     "shell.execute_reply": "2025-11-14T08:53:28.518264Z",
     "shell.execute_reply.started": "2025-11-14T08:53:28.499238Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CREATING WLASL100 LABEL MAPPING\n",
      "============================================================\n",
      "\n",
      "‚ö° Preprocessed manifest not found - creating label mapping from WLASL manifest...\n",
      "   (This is expected when using pre-trained model)\n",
      "\n",
      "‚úÖ Loaded WLASL manifest: 2038 videos\n",
      "   ‚Ä¢ Found 100 unique classes\n",
      "\n",
      "‚úÖ Created label mapping for 100 classes\n",
      "\n",
      "üìã Sample labels:\n",
      "    0 ‚Üí accident\n",
      "    1 ‚Üí africa\n",
      "    2 ‚Üí all\n",
      "    3 ‚Üí apple\n",
      "    4 ‚Üí basketball\n",
      "    5 ‚Üí bed\n",
      "    6 ‚Üí before\n",
      "    7 ‚Üí bird\n",
      "    8 ‚Üí birthday\n",
      "    9 ‚Üí black\n",
      "\n",
      "üíæ Saved label mapping to: /kaggle/working/WASL/manifests/label_mapping.json\n",
      "\n",
      "‚ö° Skipping DataLoader creation (not needed for Citizen training)\n",
      "\n",
      "============================================================\n",
      "‚úÖ CELL 10 COMPLETE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ---------- Cell 10: Create WLASL100 DataLoaders ----------\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CREATING WLASL100 LABEL MAPPING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check if we have preprocessed manifest (full pipeline)\n",
    "manifest_path = os.path.join(BASE_DIR, \"manifests\", \"wlasl100_preprocessed.csv\")\n",
    "\n",
    "if os.path.exists(manifest_path):\n",
    "    # Full pipeline: Load from preprocessed manifest\n",
    "    print(\"\\n‚úÖ Found preprocessed manifest - loading from there...\")\n",
    "    df_preprocessed = pd.read_csv(manifest_path)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Loaded manifest: {len(df_preprocessed)} videos\")\n",
    "    print(f\"   ‚Ä¢ Train: {len(df_preprocessed[df_preprocessed['split']=='train'])}\")\n",
    "    print(f\"   ‚Ä¢ Val: {len(df_preprocessed[df_preprocessed['split']=='val'])}\")\n",
    "    print(f\"   ‚Ä¢ Test: {len(df_preprocessed[df_preprocessed['split']=='test'])}\")\n",
    "    \n",
    "    # Create label mapping from preprocessed data\n",
    "    unique_glosses = sorted(df_preprocessed['gloss'].unique())\n",
    "    \n",
    "else:\n",
    "    # Quick pipeline: Load from WLASL manifest (Cell 3)\n",
    "    print(\"\\n‚ö° Preprocessed manifest not found - creating label mapping from WLASL manifest...\")\n",
    "    print(\"   (This is expected when using pre-trained model)\")\n",
    "    \n",
    "    # Load the WLASL manifest from Cell 3\n",
    "    manifest_cell3_path = os.path.join(BASE_DIR, \"manifests\", \"wlasl100_manifest.csv\")\n",
    "    \n",
    "    if not os.path.exists(manifest_cell3_path):\n",
    "        print(\"\\n‚ùå Error: WLASL manifest not found!\")\n",
    "        print(\"   Please run Cell 3 first to load the WLASL manifest.\")\n",
    "        import sys\n",
    "        sys.exit(1)\n",
    "    \n",
    "    df_wlasl = pd.read_csv(manifest_cell3_path)\n",
    "    print(f\"\\n‚úÖ Loaded WLASL manifest: {len(df_wlasl)} videos\")\n",
    "    \n",
    "    # Create label mapping from all glosses in WLASL100\n",
    "    unique_glosses = sorted(df_wlasl['gloss'].unique())\n",
    "    print(f\"   ‚Ä¢ Found {len(unique_glosses)} unique classes\")\n",
    "\n",
    "# Create label mapping (gloss name ‚Üí integer label)\n",
    "gloss_to_label = {gloss: idx for idx, gloss in enumerate(unique_glosses)}\n",
    "label_to_gloss = {idx: gloss for gloss, idx in gloss_to_label.items()}\n",
    "\n",
    "print(f\"\\n‚úÖ Created label mapping for {len(unique_glosses)} classes\")\n",
    "print(\"\\nüìã Sample labels:\")\n",
    "for i, (gloss, label) in enumerate(list(gloss_to_label.items())[:10]):\n",
    "    print(f\"   {label:2d} ‚Üí {gloss}\")\n",
    "\n",
    "# Save label mapping\n",
    "label_map_path = os.path.join(BASE_DIR, \"manifests\", \"label_mapping.json\")\n",
    "with open(label_map_path, 'w') as f:\n",
    "    json.dump({\n",
    "        'gloss_to_label': gloss_to_label,\n",
    "        'label_to_gloss': label_to_gloss,\n",
    "        'num_classes': len(gloss_to_label)\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(f\"\\nüíæ Saved label mapping to: {label_map_path}\")\n",
    "\n",
    "# Only create DataLoaders if we have preprocessed data\n",
    "if os.path.exists(manifest_path):\n",
    "    # Add numeric labels to dataframe\n",
    "    df_preprocessed['label'] = df_preprocessed['gloss'].map(gloss_to_label)\n",
    "    \n",
    "    # Create split DataFrames\n",
    "    train_df = df_preprocessed[df_preprocessed['split'] == 'train'].copy()\n",
    "    val_df = df_preprocessed[df_preprocessed['split'] == 'val'].copy()\n",
    "    test_df = df_preprocessed[df_preprocessed['split'] == 'test'].copy()\n",
    "    \n",
    "    print(\"\\nüìä Split distribution:\")\n",
    "    print(f\"   ‚Ä¢ Train: {len(train_df)} videos\")\n",
    "    print(f\"   ‚Ä¢ Val: {len(val_df)} videos\")\n",
    "    print(f\"   ‚Ä¢ Test: {len(test_df)} videos\")\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = WLASLDataset(train_df, augment=True)\n",
    "    val_dataset = WLASLDataset(val_df, augment=False)\n",
    "    test_dataset = WLASLDataset(test_df, augment=False)\n",
    "    \n",
    "    print(\"\\n‚úÖ Created datasets:\")\n",
    "    print(f\"   ‚Ä¢ Train: {len(train_dataset)} samples (augmented)\")\n",
    "    print(f\"   ‚Ä¢ Val: {len(val_dataset)} samples\")\n",
    "    print(f\"   ‚Ä¢ Test: {len(test_dataset)} samples\")\n",
    "    \n",
    "    # Create DataLoaders\n",
    "    batch_size = 8\n",
    "    num_workers = 2\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n‚úÖ Created DataLoaders (batch_size={batch_size}):\")\n",
    "    print(f\"   ‚Ä¢ Train: {len(train_loader)} batches\")\n",
    "    print(f\"   ‚Ä¢ Val: {len(val_loader)} batches\")\n",
    "    print(f\"   ‚Ä¢ Test: {len(test_loader)} batches\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Ready for training (Cell 11)\")\n",
    "else:\n",
    "    print(\"\\n‚ö° Skipping DataLoader creation (not needed for Citizen training)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ CELL 10 COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ---------- Cell 11: Training Loop (Official WLASL Config) ----------\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Check if model exists\n",
    "if 'model' not in dir():\n",
    "    raise RuntimeError(\"‚ùå ERROR: Model not found! Run Cell 8 (Load I3D Model) first!\")\n",
    "\n",
    "# Check if dataloaders exist\n",
    "if 'train_loader' not in dir() or 'val_loader' not in dir():\n",
    "    raise RuntimeError(\"‚ùå ERROR: DataLoaders not found! Run Cell 9 (Create DataLoaders) first!\")\n",
    "\n",
    "print(\"‚úÖ Model and DataLoaders found\")\n",
    "\n",
    "# Clear CUDA cache\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"üîÑ CUDA cache cleared\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Training config - OFFICIAL WLASL SETTINGS\n",
    "config = {\n",
    "    'num_epochs': 100,\n",
    "    'learning_rate': 1e-4,  # Official WLASL\n",
    "    'weight_decay': 1e-8,   # Official WLASL \n",
    "    'adam_eps': 1e-3,       # Official WLASL\n",
    "    'patience': 10,\n",
    "    'grad_clip': 1.0,\n",
    "    'use_amp': False,      \n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING SETUP (OFFICIAL WLASL CONFIG)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Epochs: {config['num_epochs']}\")\n",
    "print(f\"LR: {config['learning_rate']} | Weight Decay: {config['weight_decay']}\")\n",
    "print(f\"Train batches: {len(train_loader)} | Val batches: {len(val_loader)}\")\n",
    "\n",
    "# Optimizer - OFFICIAL WLASL USES ADAM (NOT AdamW) with SAME LR for all layers\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=config['learning_rate'],\n",
    "    weight_decay=config['weight_decay'],\n",
    "    eps=config['adam_eps']\n",
    ")\n",
    "\n",
    "# Learning rate scheduler - OFFICIAL WLASL USES ReduceLROnPlateau\n",
    "\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    patience=5,\n",
    "    factor=0.3,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training tracking\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'learning_rates': []}\n",
    "best_val_loss = float('inf')\n",
    "best_val_acc = 0.0\n",
    "patience_counter = 0\n",
    "best_epoch = 0\n",
    "checkpoint_dir = os.path.join(BASE_DIR, \"models\", \"checkpoints\")\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device, epoch):\n",
    "    \"\"\"Train for one epoch - Official WLASL style (no FP16, standard PyTorch).\"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1} [Train]\")\n",
    "    \n",
    "    for batch_idx, batch in enumerate(pbar):\n",
    "        frames = batch['frames'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(frames)\n",
    "        \n",
    "        # I3D outputs: [batch, classes, time] - average over time\n",
    "        if outputs.dim() == 3:\n",
    "            outputs = outputs.mean(dim=2)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), config['grad_clip'])\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate accuracy (move to CPU for computation)\n",
    "        with torch.no_grad():\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        avg_loss = running_loss / (batch_idx + 1)\n",
    "        avg_acc = 100 * correct / total\n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{avg_loss:.4f}',\n",
    "            'acc': f'{avg_acc:.2f}%'\n",
    "        })\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def validate(model, dataloader, criterion, device, epoch):\n",
    "    \"\"\"Validate on validation set - Official WLASL style.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1} [Val]  \")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(pbar):\n",
    "            frames = batch['frames'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            outputs = model(frames)\n",
    "            \n",
    "            # I3D outputs: [batch, classes, time] - average over time\n",
    "            if outputs.dim() == 3:\n",
    "                outputs = outputs.mean(dim=2)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            avg_loss = running_loss / (batch_idx + 1)\n",
    "            avg_acc = 100 * correct / total\n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{avg_loss:.4f}',\n",
    "                'acc': f'{avg_acc:.2f}%'\n",
    "            })\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# Main training loop\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(config['num_epochs']):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(\n",
    "        model, train_loader, criterion, optimizer, device, epoch\n",
    "    )\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc = validate(\n",
    "        model, val_loader, criterion, device, epoch\n",
    "    )\n",
    "    \n",
    "    # Update scheduler (ReduceLROnPlateau - needs val_loss)\n",
    "    scheduler.step(val_loss)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['learning_rates'].append(current_lr)\n",
    "    \n",
    "    # Calculate times\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Epoch {epoch+1}/{config['num_epochs']} Summary:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.2f}%\")\n",
    "    print(f\"Learning Rate: {current_lr:.6f}\")\n",
    "    print(f\"Epoch Time: {epoch_time:.1f}s | Total Time: {elapsed_time/60:.1f}min\")\n",
    "    \n",
    "    # GPU memory stats\n",
    "    if epoch == 0:\n",
    "        allocated = torch.cuda.memory_allocated(0) / 1e9\n",
    "        reserved = torch.cuda.memory_reserved(0) / 1e9\n",
    "        print(f\"GPU Memory: {allocated:.2f} GB allocated, {reserved:.2f} GB reserved\")\n",
    "    \n",
    "    # Check if best model\n",
    "    is_best = val_acc > best_val_acc\n",
    "    \n",
    "    if is_best:\n",
    "        best_val_acc = val_acc\n",
    "        best_val_loss = val_loss\n",
    "        best_epoch = epoch + 1\n",
    "        patience_counter = 0\n",
    "        \n",
    "        # Save best model\n",
    "        best_model_path = os.path.join(checkpoint_dir, \"best_model.pth\")\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc,\n",
    "            'history': history\n",
    "        }, best_model_path)\n",
    "        \n",
    "        print(f\"‚úÖ New best model saved! (Val Acc: {val_acc:.2f}%)\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"‚è≥ No improvement. Patience: {patience_counter}/{config['patience']}\")\n",
    "    \n",
    "    print(f\"üèÜ Best Val Acc so far: {best_val_acc:.2f}% (Epoch {best_epoch})\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if patience_counter >= config['patience']:\n",
    "        print(f\"\\nüõë Early stopping triggered after {epoch+1} epochs\")\n",
    "        print(f\"   No improvement for {config['patience']} epochs\")\n",
    "        print(f\"   Best model from epoch {best_epoch} will be used\")\n",
    "        break\n",
    "    \n",
    "    # Save checkpoint every 5 epochs\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_epoch_{epoch+1}.pth\")\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'history': history\n",
    "        }, checkpoint_path)\n",
    "        print(f\"üíæ Checkpoint saved: epoch_{epoch+1}.pth\\n\")\n",
    "    \n",
    "    # Clear cache every 3 epochs (helps with memory fragmentation)\n",
    "    if (epoch + 1) % 3 == 0:\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# Training complete\n",
    "total_time = time.time() - start_time\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nüìä Final Results:\")\n",
    "print(f\"   ‚Ä¢ Total epochs: {len(history['train_loss'])}\")\n",
    "print(f\"   ‚Ä¢ Total time: {total_time/60:.1f} minutes\")\n",
    "print(f\"   ‚Ä¢ Best validation accuracy: {best_val_acc:.2f}% (Epoch {best_epoch})\")\n",
    "print(f\"   ‚Ä¢ Best validation loss: {best_val_loss:.4f}\")\n",
    "print(f\"\\n   ‚Ä¢ Final train accuracy: {history['train_acc'][-1]:.2f}%\")\n",
    "print(f\"   ‚Ä¢ Final val accuracy: {history['val_acc'][-1]:.2f}%\")\n",
    "\n",
    "# Load best model\n",
    "print(f\"\\nüîÑ Loading best model (epoch {best_epoch})...\")\n",
    "best_checkpoint = torch.load(os.path.join(checkpoint_dir, \"best_model.pth\"))\n",
    "model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "print(\"‚úÖ Best model loaded\")\n",
    "\n",
    "# Save training history\n",
    "history_path = os.path.join(BASE_DIR, \"models\", \"training_history.json\")\n",
    "with open(history_path, 'w') as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "print(f\"\\nüíæ Training history saved to: {history_path}\")\n",
    "print(\"\\n‚úÖ Ready for next cell - evaluation on test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T08:53:47.1001Z",
     "iopub.status.busy": "2025-11-14T08:53:47.099567Z",
     "iopub.status.idle": "2025-11-14T08:53:49.008281Z",
     "shell.execute_reply": "2025-11-14T08:53:49.007623Z",
     "shell.execute_reply.started": "2025-11-14T08:53:47.100076Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LOADING ASL CITIZEN DATASET\n",
      "============================================================\n",
      "‚úÖ ASL Citizen dataset found!\n",
      "   Path: /kaggle/input/asl-citizen\n",
      "‚úÖ Found ASL_Citizen subdirectory!\n",
      "\n",
      "‚úÖ Found 83399 videos\n",
      "‚úÖ ASL Citizen paths configured:\n",
      "   ‚Ä¢ Videos: /kaggle/input/asl-citizen/ASL_Citizen/videos\n",
      "   ‚Ä¢ Splits: /kaggle/input/asl-citizen/ASL_Citizen/splits\n",
      "\n",
      "============================================================\n",
      "‚úÖ ASL Citizen dataset loaded\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ---------- Cell 12: Load ASL Citizen Dataset ----------\n",
    "import json\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"LOADING ASL CITIZEN DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check if ASL Citizen dataset is added as Kaggle input\n",
    "CITIZEN_INPUT = \"/kaggle/input/asl-citizen\"\n",
    "\n",
    "if os.path.exists(CITIZEN_INPUT):\n",
    "    print(\"‚úÖ ASL Citizen dataset found!\")\n",
    "    print(f\"   Path: {CITIZEN_INPUT}\")\n",
    "    \n",
    "    # Check for ASL_Citizen subdirectory\n",
    "    asl_citizen_subdir = os.path.join(CITIZEN_INPUT, \"ASL_Citizen\")\n",
    "    if os.path.exists(asl_citizen_subdir):\n",
    "        CITIZEN_ROOT = asl_citizen_subdir\n",
    "        print(\"‚úÖ Found ASL_Citizen subdirectory!\")\n",
    "    else:\n",
    "        CITIZEN_ROOT = CITIZEN_INPUT\n",
    "        print(\"‚ö†Ô∏è No ASL_Citizen subdirectory, using root\")\n",
    "    \n",
    "    # Check videos and splits folders\n",
    "    CITIZEN_VIDEOS = os.path.join(CITIZEN_ROOT, \"videos\")\n",
    "    CITIZEN_SPLITS = os.path.join(CITIZEN_ROOT, \"splits\")\n",
    "    \n",
    "    if os.path.exists(CITIZEN_VIDEOS) and os.path.exists(CITIZEN_SPLITS):\n",
    "        video_count = len([f for f in os.listdir(CITIZEN_VIDEOS) if f.endswith(('.mp4', '.MP4'))])\n",
    "        print(f\"\\n‚úÖ Found {video_count} videos\")\n",
    "        print(\"‚úÖ ASL Citizen paths configured:\")\n",
    "        print(f\"   ‚Ä¢ Videos: {CITIZEN_VIDEOS}\")\n",
    "        print(f\"   ‚Ä¢ Splits: {CITIZEN_SPLITS}\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå ERROR: Required folders not found!\")\n",
    "        import sys\n",
    "        sys.exit(1)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è ASL Citizen dataset not found in inputs!\")\n",
    "    print(\"\\nüìù To add the dataset:\")\n",
    "    print(\"   1. Click 'Add Data' button\")\n",
    "    print(\"   2. Search for 'asl-citizen'\")\n",
    "    print(\"   3. Add and rerun\")\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ ASL Citizen dataset loaded\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T08:53:56.064087Z",
     "iopub.status.busy": "2025-11-14T08:53:56.063831Z",
     "iopub.status.idle": "2025-11-14T08:54:00.425906Z",
     "shell.execute_reply": "2025-11-14T08:54:00.425225Z",
     "shell.execute_reply.started": "2025-11-14T08:53:56.064066Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PREPARING CITIZEN 100 LABEL DATASET (OPTIMIZED)\n",
      "============================================================\n",
      "\n",
      "‚úÖ Loaded WLASL100 labels: 100 glosses\n",
      "\n",
      "üîç Building video filename index...\n",
      "‚úÖ Indexed 4593 unique glosses\n",
      "   ‚Ä¢ Total videos: 83399\n",
      "\n",
      "üîç Matching CSV splits with videos...\n",
      "\n",
      "üìã Parsing train.csv: 40154 rows\n",
      "\n",
      "üìã Parsing val.csv: 10304 rows\n",
      "\n",
      "üìã Parsing test.csv: 32941 rows\n",
      "\n",
      "‚úÖ Matched 2018 unique glosses\n",
      "   ‚Ä¢ Total videos: 71943\n",
      "\n",
      "============================================================\n",
      "OPTIMIZED STRATEGY: WLASL INTERSECT + TOP NON-INTERSECT\n",
      "============================================================\n",
      "\n",
      "1Ô∏è‚É£ WLASL100 ‚à© Citizen: 98 glosses\n",
      "   ‚Ä¢ Total videos: 4129\n",
      "\n",
      "2Ô∏è‚É£ Adding top 2 non-intersect glosses:\n",
      "   ‚Ä¢ shave: 148 videos\n",
      "   ‚Ä¢ erase: 147 videos\n",
      "\n",
      "‚úÖ FINAL SELECTION: 100 glosses\n",
      "   ‚Ä¢ WLASL intersect: 98\n",
      "   ‚Ä¢ Additional: 2\n",
      "   ‚Ä¢ WLASL overlap: 98/100 (98.0%)\n",
      "\n",
      "üìä Citizen 100 dataset:\n",
      "   ‚Ä¢ Total videos: 4424\n",
      "   ‚Ä¢ Train: 2192\n",
      "   ‚Ä¢ Val: 560\n",
      "   ‚Ä¢ Test: 1672\n",
      "\n",
      "üíæ Saved:\n",
      "   ‚Ä¢ /kaggle/working/WASL/manifests/citizen_100.csv\n",
      "   ‚Ä¢ /kaggle/working/WASL/manifests/label_mapping_100.json\n",
      "   ‚Ä¢ /kaggle/working/WASL/manifests/wlasl_citizen_intersection.json\n",
      "\n",
      "============================================================\n",
      "‚úÖ OPTIMIZED STRATEGY APPLIED!\n",
      "‚úÖ 100 total glosses\n",
      "‚úÖ 98/100 WLASL100 glosses included\n",
      "‚úÖ MAXIMUM transfer learning overlap!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ---------- Cell 13: Parse Citizen & Prepare 100 Labels (OPTIMIZED) ----------\n",
    "import json\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PREPARING CITIZEN 100 LABEL DATASET (OPTIMIZED)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load WLASL100 labels (REQUIRED for this strategy)\n",
    "wlasl_label_path = os.path.join(BASE_DIR, \"manifests\", \"label_mapping.json\")\n",
    "if os.path.exists(wlasl_label_path):\n",
    "    with open(wlasl_label_path, 'r') as f:\n",
    "        wlasl_mapping = json.load(f)\n",
    "    wlasl100_glosses = set(wlasl_mapping['gloss_to_label'].keys())\n",
    "    print(f\"\\n‚úÖ Loaded WLASL100 labels: {len(wlasl100_glosses)} glosses\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Error: WLASL100 labels not found!\")\n",
    "    print(\"   Please run Cell 3 and Cell 10 first.\")\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "# Citizen dataset paths\n",
    "CITIZEN_BASE = \"/kaggle/input/asl-citizen/ASL_Citizen\"\n",
    "CITIZEN_VIDEOS = os.path.join(CITIZEN_BASE, \"videos\")\n",
    "CITIZEN_SPLITS = os.path.join(CITIZEN_BASE, \"splits\")\n",
    "\n",
    "print(\"\\nüîç Building video filename index...\")\n",
    "\n",
    "# Build video filename index: gloss -> list of video filenames\n",
    "# Format: \"000017451997373907346-LIBRARY.mp4\" -> gloss = \"library\"\n",
    "from collections import defaultdict\n",
    "\n",
    "video_files_by_gloss = defaultdict(list)\n",
    "\n",
    "for video_file in os.listdir(CITIZEN_VIDEOS):\n",
    "    if not video_file.endswith(('.mp4', '.MP4')):\n",
    "        continue\n",
    "    \n",
    "    # Extract gloss from filename: \"000017451997373907346-LIBRARY.mp4\" -> \"library\"\n",
    "    if '-' in video_file:\n",
    "        gloss_part = video_file.split('-')[-1].replace('.mp4', '').replace('.MP4', '')\n",
    "        gloss = ''.join([c for c in gloss_part if not c.isdigit()]).strip().lower()\n",
    "        video_files_by_gloss[gloss].append(video_file)\n",
    "\n",
    "print(f\"‚úÖ Indexed {len(video_files_by_gloss)} unique glosses\")\n",
    "print(f\"   ‚Ä¢ Total videos: {sum(len(v) for v in video_files_by_gloss.values())}\")\n",
    "\n",
    "# Parse splits and match with videos\n",
    "print(\"\\nüîç Matching CSV splits with videos...\")\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "citizen_inventory = defaultdict(list)\n",
    "\n",
    "for split_file in ['train.csv', 'val.csv', 'test.csv']:\n",
    "    split_path = os.path.join(CITIZEN_SPLITS, split_file)\n",
    "    if not os.path.exists(split_path):\n",
    "        continue\n",
    "    \n",
    "    split_name = split_file.replace('.csv', '')\n",
    "    df_split = pd.read_csv(split_path)\n",
    "    \n",
    "    print(f\"\\nüìã Parsing {split_file}: {len(df_split)} rows\")\n",
    "    \n",
    "    gloss_column = 'Gloss' if 'Gloss' in df_split.columns else df_split.columns[0]\n",
    "    \n",
    "    for idx, row in df_split.iterrows():\n",
    "        gloss_raw = str(row[gloss_column])\n",
    "        \n",
    "        # Clean: \"APPLE\" -> \"apple\", \"SOCCER2\" -> \"soccer\"\n",
    "        gloss = ''.join([c for c in gloss_raw if not c.isdigit()]).strip().lower()\n",
    "        \n",
    "        # Check if we have videos for this gloss\n",
    "        if gloss in video_files_by_gloss and len(video_files_by_gloss[gloss]) > 0:\n",
    "            # Take first available video\n",
    "            video_filename = video_files_by_gloss[gloss].pop(0)\n",
    "            video_path = os.path.join(CITIZEN_VIDEOS, video_filename)\n",
    "            video_id = video_filename.replace('.mp4', '').replace('.MP4', '')\n",
    "            \n",
    "            citizen_inventory[gloss].append({\n",
    "                'video_id': video_id,\n",
    "                'video_filename': video_filename,\n",
    "                'video_path': video_path,\n",
    "                'split': split_name,\n",
    "                'gloss': gloss\n",
    "            })\n",
    "\n",
    "# Count videos per gloss\n",
    "gloss_counts = {gloss: len(videos) for gloss, videos in citizen_inventory.items()}\n",
    "print(f\"\\n‚úÖ Matched {len(gloss_counts)} unique glosses\")\n",
    "print(f\"   ‚Ä¢ Total videos: {sum(gloss_counts.values())}\")\n",
    "\n",
    "# STRATEGY: WLASL intersect + top non-intersect = 100\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"OPTIMIZED STRATEGY: WLASL INTERSECT + TOP NON-INTERSECT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Find WLASL100 intersection\n",
    "citizen_glosses = set(gloss_counts.keys())\n",
    "intersection = wlasl100_glosses.intersection(citizen_glosses)\n",
    "\n",
    "print(f\"\\n1Ô∏è‚É£ WLASL100 ‚à© Citizen: {len(intersection)} glosses\")\n",
    "intersection_videos = sum([gloss_counts[g] for g in intersection])\n",
    "print(f\"   ‚Ä¢ Total videos: {intersection_videos}\")\n",
    "\n",
    "# 2. Get top non-intersect glosses by video count\n",
    "non_intersect_glosses = [g for g in citizen_glosses if g not in intersection]\n",
    "non_intersect_sorted = sorted(non_intersect_glosses, key=lambda g: gloss_counts[g], reverse=True)\n",
    "\n",
    "# Select to fill to 100\n",
    "num_to_add = 100 - len(intersection)\n",
    "if num_to_add > 0:\n",
    "    additional_glosses = non_intersect_sorted[:num_to_add]\n",
    "    print(f\"\\n2Ô∏è‚É£ Adding top {num_to_add} non-intersect glosses:\")\n",
    "    for g in additional_glosses[:5]:\n",
    "        print(f\"   ‚Ä¢ {g}: {gloss_counts[g]} videos\")\n",
    "    if num_to_add > 5:\n",
    "        print(f\"   ‚Ä¢ ... and {num_to_add - 5} more\")\n",
    "else:\n",
    "    additional_glosses = []\n",
    "    print(\"\\n2Ô∏è‚É£ No additional glosses needed\")\n",
    "\n",
    "# 3. Combine final selection\n",
    "selected_glosses = list(intersection) + additional_glosses\n",
    "\n",
    "print(f\"\\n‚úÖ FINAL SELECTION: {len(selected_glosses)} glosses\")\n",
    "print(f\"   ‚Ä¢ WLASL intersect: {len(intersection)}\")\n",
    "print(f\"   ‚Ä¢ Additional: {len(additional_glosses)}\")\n",
    "print(f\"   ‚Ä¢ WLASL overlap: {len(intersection)}/{len(wlasl100_glosses)} ({len(intersection)/len(wlasl100_glosses)*100:.1f}%)\")\n",
    "\n",
    "# 4. Extract all videos for selected glosses\n",
    "citizen_records = []\n",
    "for gloss in selected_glosses:\n",
    "    for video_info in citizen_inventory[gloss]:\n",
    "        citizen_records.append({\n",
    "            'video_id': video_info['video_id'],\n",
    "            'video_filename': video_info['video_filename'],\n",
    "            'gloss': gloss,\n",
    "            'split': video_info['split'],\n",
    "            'video_path': video_info['video_path'],\n",
    "            'dataset': 'citizen'\n",
    "        })\n",
    "\n",
    "df_citizen_100 = pd.DataFrame(citizen_records)\n",
    "\n",
    "print(\"\\nüìä Citizen 100 dataset:\")\n",
    "print(f\"   ‚Ä¢ Total videos: {len(df_citizen_100)}\")\n",
    "print(f\"   ‚Ä¢ Train: {len(df_citizen_100[df_citizen_100['split']=='train'])}\")\n",
    "print(f\"   ‚Ä¢ Val: {len(df_citizen_100[df_citizen_100['split']=='val'])}\")\n",
    "print(f\"   ‚Ä¢ Test: {len(df_citizen_100[df_citizen_100['split']=='test'])}\")\n",
    "\n",
    "# Create label mapping\n",
    "unique_glosses_final = sorted(df_citizen_100['gloss'].unique())\n",
    "gloss_to_label_final = {gloss: idx for idx, gloss in enumerate(unique_glosses_final)}\n",
    "label_to_gloss_final = {idx: gloss for gloss, idx in gloss_to_label_final.items()}\n",
    "\n",
    "df_citizen_100['label'] = df_citizen_100['gloss'].map(gloss_to_label_final)\n",
    "\n",
    "# Save manifest and label mapping\n",
    "citizen_manifest = os.path.join(BASE_DIR, \"manifests\", \"citizen_100.csv\")\n",
    "df_citizen_100.to_csv(citizen_manifest, index=False)\n",
    "\n",
    "label_map_path = os.path.join(BASE_DIR, \"manifests\", \"label_mapping_100.json\")\n",
    "with open(label_map_path, 'w') as f:\n",
    "    json.dump({\n",
    "        'gloss_to_label': gloss_to_label_final,\n",
    "        'label_to_gloss': label_to_gloss_final,\n",
    "        'num_classes': len(gloss_to_label_final),\n",
    "        'intersection_labels': list(intersection),\n",
    "        'additional_labels': additional_glosses,\n",
    "        'total_wlasl_overlap': len(intersection)\n",
    "    }, f, indent=2)\n",
    "\n",
    "# Save intersection analysis\n",
    "intersection_analysis = {\n",
    "    'wlasl100_total': len(wlasl100_glosses),\n",
    "    'citizen_total': len(citizen_glosses),\n",
    "    'intersection_count': len(intersection),\n",
    "    'intersection_labels': sorted(list(intersection)),\n",
    "    'missing_from_citizen': sorted(list(wlasl100_glosses - citizen_glosses)),\n",
    "    'citizen_final_count': len(selected_glosses),\n",
    "    'citizen_final_wlasl_overlap': len(intersection)\n",
    "}\n",
    "\n",
    "intersection_path = os.path.join(BASE_DIR, \"manifests\", \"wlasl_citizen_intersection.json\")\n",
    "with open(intersection_path, 'w') as f:\n",
    "    json.dump(intersection_analysis, f, indent=2)\n",
    "\n",
    "print(\"\\nüíæ Saved:\")\n",
    "print(f\"   ‚Ä¢ {citizen_manifest}\")\n",
    "print(f\"   ‚Ä¢ {label_map_path}\")\n",
    "print(f\"   ‚Ä¢ {intersection_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ OPTIMIZED STRATEGY APPLIED!\")\n",
    "print(f\"‚úÖ {len(selected_glosses)} total glosses\")\n",
    "print(f\"‚úÖ {len(intersection)}/{len(wlasl100_glosses)} WLASL100 glosses included\")\n",
    "print(\"‚úÖ MAXIMUM transfer learning overlap!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T09:39:20.143518Z",
     "iopub.status.busy": "2025-11-14T09:39:20.142945Z",
     "iopub.status.idle": "2025-11-14T10:04:27.815953Z",
     "shell.execute_reply": "2025-11-14T10:04:27.815249Z",
     "shell.execute_reply.started": "2025-11-14T09:39:20.143489Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PREPROCESSING CITIZEN 100 VIDEOS\n",
      "============================================================\n",
      "\n",
      "üí° Using SAME config as WLASL (32 frames):\n",
      "   ‚Ä¢ Frames: 32\n",
      "   ‚Ä¢ Size: (224, 224)\n",
      "   ‚Ä¢ Perfect consistency with I3D pretraining & WLASL100!\n",
      "\n",
      "üìÅ Output: /kaggle/working/WASL/preprocessed_citizen_100\n",
      "‚ö†Ô∏è ONLY processing train + val (test skipped to save ~2GB storage)\n",
      "\n",
      "üìä Found 1698 already preprocessed videos:\n",
      "   ‚Ä¢ train: 1698 videos\n",
      "   ‚Ä¢ val: 0 videos\n",
      "\n",
      "üí° These videos will be SKIPPED (fast!)\n",
      "\n",
      "============================================================\n",
      "Processing TRAIN split: 2192 videos\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2192/2192 [12:19<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ TRAIN complete:\n",
      "   ‚Ä¢ Total: 2192\n",
      "   ‚Ä¢ Skipped: 1698\n",
      "   ‚Ä¢ Newly processed: 494\n",
      "   ‚Ä¢ Failed: 0\n",
      "\n",
      "============================================================\n",
      "Processing VAL split: 560 videos\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 560/560 [12:48<00:00,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ VAL complete:\n",
      "   ‚Ä¢ Total: 560\n",
      "   ‚Ä¢ Skipped: 0\n",
      "   ‚Ä¢ Newly processed: 560\n",
      "   ‚Ä¢ Failed: 0\n",
      "\n",
      "============================================================\n",
      "PREPROCESSING COMPLETE (Train + Val only)\n",
      "============================================================\n",
      "\n",
      "üìä Statistics:\n",
      "   ‚Ä¢ Total processed: 2752\n",
      "   ‚Ä¢ Train: 2192\n",
      "   ‚Ä¢ Val: 560\n",
      "   ‚Ä¢ Failed: 0\n",
      "\n",
      "üíæ Storage: 8.17 GB\n",
      "   ‚Ä¢ Avg per video: 3.04 MB\n",
      "\n",
      "‚úÖ Manifest saved: /kaggle/working/WASL/manifests/citizen_100_preprocessed.csv\n",
      "\n",
      "‚úÖ Ready for Cell 15 - Create DataLoaders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------- Cell 14: Preprocess Citizen 100 Videos ----------\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PREPROCESSING CITIZEN 100 VIDEOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define preprocessing config (SAME AS WLASL - 32 FRAMES!)\n",
    "PREPROCESS_CONFIG = {\n",
    "    'target_fps': 25,\n",
    "    'target_frames': 32,  # SAME as WLASL and I3D pretraining!\n",
    "    'target_size': (224, 224),\n",
    "    'normalize': True,\n",
    "}\n",
    "\n",
    "print(\"\\nüí° Using SAME config as WLASL (32 frames):\")\n",
    "print(f\"   ‚Ä¢ Frames: {PREPROCESS_CONFIG['target_frames']}\")\n",
    "print(f\"   ‚Ä¢ Size: {PREPROCESS_CONFIG['target_size']}\")\n",
    "print(\"   ‚Ä¢ Perfect consistency with I3D pretraining & WLASL100!\")\n",
    "\n",
    "# Load video utility function\n",
    "def load_video_frames(video_path, target_frames=32, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Load video and extract uniformly sampled frames.\n",
    "    \n",
    "    Args:\n",
    "        video_path: Path to video file\n",
    "        target_frames: Number of frames to extract\n",
    "        target_size: Target spatial size (H, W)\n",
    "    \n",
    "    Returns:\n",
    "        frames: numpy array of shape (T, H, W, C) - uint8 [0-255]\n",
    "        original_frames: original frame count\n",
    "        original_fps: original FPS\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(f\"Cannot open video: {video_path}\")\n",
    "    \n",
    "    # Get video properties\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # Calculate frame indices to sample uniformly\n",
    "    if total_frames < target_frames:\n",
    "        indices = np.linspace(0, total_frames - 1, target_frames, dtype=int)\n",
    "    else:\n",
    "        indices = np.linspace(0, total_frames - 1, target_frames, dtype=int)\n",
    "    \n",
    "    frames = []\n",
    "    for idx in indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            if len(frames) > 0:\n",
    "                frame = frames[-1].copy()\n",
    "            else:\n",
    "                raise ValueError(f\"Cannot read frame {idx} from {video_path}\")\n",
    "        \n",
    "        # Convert BGR to RGB\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Resize to target size\n",
    "        frame = cv2.resize(frame, target_size, interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "        frames.append(frame)\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    # Stack frames: (T, H, W, C)\n",
    "    frames = np.stack(frames, axis=0).astype(np.uint8)\n",
    "    \n",
    "    return frames, total_frames, fps\n",
    "\n",
    "# Create directories (ONLY train and val - no test to save storage!)\n",
    "CITIZEN_PREPROCESSED = os.path.join(BASE_DIR, \"preprocessed_citizen_100\")\n",
    "for split in ['train', 'val']:\n",
    "    os.makedirs(os.path.join(CITIZEN_PREPROCESSED, split), exist_ok=True)\n",
    "\n",
    "print(f\"\\nüìÅ Output: {CITIZEN_PREPROCESSED}\")\n",
    "print(\"‚ö†Ô∏è ONLY processing train + val (test skipped to save ~2GB storage)\")\n",
    "\n",
    "# Check existing preprocessed videos (SMART SKIP)\n",
    "existing_counts = {}\n",
    "for split_name in ['train', 'val']:\n",
    "    split_dir = os.path.join(CITIZEN_PREPROCESSED, split_name)\n",
    "    existing_counts[split_name] = len(list(Path(split_dir).glob(\"*.npz\")))\n",
    "\n",
    "total_existing = sum(existing_counts.values())\n",
    "print(f\"\\nüìä Found {total_existing} already preprocessed videos:\")\n",
    "for split_name, count in existing_counts.items():\n",
    "    print(f\"   ‚Ä¢ {split_name}: {count} videos\")\n",
    "\n",
    "if total_existing > 0:\n",
    "    print(\"\\nüí° These videos will be SKIPPED (fast!)\")\n",
    "\n",
    "# Process ONLY train and val splits\n",
    "processed_records = []\n",
    "failed_videos = []\n",
    "\n",
    "for split in ['train', 'val']:\n",
    "    df_split = df_citizen_100[df_citizen_100['split'] == split].copy()\n",
    "    \n",
    "    if len(df_split) == 0:\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing {split.upper()} split: {len(df_split)} videos\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    split_dir = os.path.join(CITIZEN_PREPROCESSED, split)\n",
    "    skipped_videos = 0\n",
    "    \n",
    "    for idx, row in tqdm(df_split.iterrows(), total=len(df_split), desc=f\"{split}\"):\n",
    "        video_id = row['video_id']\n",
    "        video_path = row['video_path']\n",
    "        gloss = row['gloss']\n",
    "        \n",
    "        # Smart skip: check if already preprocessed\n",
    "        save_path = os.path.join(split_dir, f\"{video_id}.npz\")\n",
    "        \n",
    "        if os.path.exists(save_path):\n",
    "            # Skip processing - load metadata\n",
    "            try:\n",
    "                data = np.load(save_path)\n",
    "                frames = data['frames']\n",
    "                \n",
    "                processed_records.append({\n",
    "                    'video_id': video_id,\n",
    "                    'gloss': gloss,\n",
    "                    'split': split,\n",
    "                    'save_path': save_path,\n",
    "                    'original_frames': -1,\n",
    "                    'original_fps': -1,\n",
    "                    'processed_frames': frames.shape[0],\n",
    "                    'frame_shape': frames.shape[1:],\n",
    "                    'dataset': 'citizen'\n",
    "                })\n",
    "                skipped_videos += 1\n",
    "                continue\n",
    "                \n",
    "            except Exception:\n",
    "                print(f\"\\n‚ö†Ô∏è Corrupted file {video_id}, reprocessing...\")\n",
    "        \n",
    "        try:\n",
    "            # Load and preprocess video (32 frames)\n",
    "            frames, orig_frames, orig_fps = load_video_frames(\n",
    "                video_path,\n",
    "                target_frames=PREPROCESS_CONFIG['target_frames'],\n",
    "                target_size=PREPROCESS_CONFIG['target_size']\n",
    "            )\n",
    "            \n",
    "            # Save as compressed .npz (uint8 for storage efficiency)\n",
    "            np.savez_compressed(save_path, frames=frames)\n",
    "            \n",
    "            # Record metadata\n",
    "            processed_records.append({\n",
    "                'video_id': video_id,\n",
    "                'gloss': gloss,\n",
    "                'split': split,\n",
    "                'save_path': save_path,\n",
    "                'original_frames': orig_frames,\n",
    "                'original_fps': orig_fps,\n",
    "                'processed_frames': frames.shape[0],\n",
    "                'frame_shape': frames.shape[1:],\n",
    "                'dataset': 'citizen'\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            failed_videos.append({\n",
    "                'video_id': video_id,\n",
    "                'gloss': gloss,\n",
    "                'error': str(e)\n",
    "            })\n",
    "            print(f\"\\n‚ö†Ô∏è Failed: {video_id} ({gloss}): {e}\")\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\n‚úÖ {split.upper()} complete:\")\n",
    "    print(f\"   ‚Ä¢ Total: {len(df_split)}\")\n",
    "    print(f\"   ‚Ä¢ Skipped: {skipped_videos}\")\n",
    "    print(f\"   ‚Ä¢ Newly processed: {len([r for r in processed_records if r['split']==split]) - skipped_videos}\")\n",
    "    print(f\"   ‚Ä¢ Failed: {len([f for f in failed_videos if f.get('split')==split])}\")\n",
    "\n",
    "# Create preprocessed manifest\n",
    "df_preprocessed_citizen = pd.DataFrame(processed_records)\n",
    "\n",
    "# Save manifest\n",
    "citizen_preprocessed_manifest = os.path.join(BASE_DIR, \"manifests\", \"citizen_100_preprocessed.csv\")\n",
    "df_preprocessed_citizen.to_csv(citizen_preprocessed_manifest, index=False)\n",
    "\n",
    "# Calculate storage (train + val only)\n",
    "total_size = 0\n",
    "for split_name in ['train', 'val']:\n",
    "    split_dir = os.path.join(CITIZEN_PREPROCESSED, split_name)\n",
    "    for npz_file in Path(split_dir).glob(\"*.npz\"):\n",
    "        total_size += npz_file.stat().st_size\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PREPROCESSING COMPLETE (Train + Val only)\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nüìä Statistics:\")\n",
    "print(f\"   ‚Ä¢ Total processed: {len(df_preprocessed_citizen)}\")\n",
    "print(f\"   ‚Ä¢ Train: {len([r for r in processed_records if r['split']=='train'])}\")\n",
    "print(f\"   ‚Ä¢ Val: {len([r for r in processed_records if r['split']=='val'])}\")\n",
    "print(f\"   ‚Ä¢ Failed: {len(failed_videos)}\")\n",
    "\n",
    "print(f\"\\nüíæ Storage: {total_size / (1024**3):.2f} GB\")\n",
    "print(f\"   ‚Ä¢ Avg per video: {total_size / len(df_preprocessed_citizen) / (1024**2):.2f} MB\")\n",
    "\n",
    "print(f\"\\n‚úÖ Manifest saved: {citizen_preprocessed_manifest}\")\n",
    "print(\"\\n‚úÖ Ready for Cell 15 - Create DataLoaders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T10:35:12.885107Z",
     "iopub.status.busy": "2025-11-14T10:35:12.884406Z",
     "iopub.status.idle": "2025-11-14T10:35:12.900566Z",
     "shell.execute_reply": "2025-11-14T10:35:12.899858Z",
     "shell.execute_reply.started": "2025-11-14T10:35:12.885083Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFYING CELL 14 OUTPUT\n",
      "============================================================\n",
      "\n",
      "üìÅ Manifests directory: /kaggle/working/WASL/manifests\n",
      "   Exists: True\n",
      "\n",
      "üìÑ Files in manifests:\n",
      "   ‚Ä¢ label_mapping_100.json (0.00 MB)\n",
      "   ‚Ä¢ wlasl100_available.csv (0.10 MB)\n",
      "   ‚Ä¢ label_mapping.json (0.00 MB)\n",
      "   ‚Ä¢ wlasl100_manifest.csv (0.09 MB)\n",
      "   ‚Ä¢ citizen_100.csv (0.62 MB)\n",
      "   ‚Ä¢ wlasl_citizen_intersection.json (0.00 MB)\n",
      "   ‚Ä¢ citizen_100_preprocessed.csv (0.40 MB)\n",
      "\n",
      "üìÅ Preprocessed directory: /kaggle/working/WASL/preprocessed_citizen_100\n",
      "   Exists: True\n",
      "   ‚Ä¢ train: 2192 videos\n",
      "   ‚Ä¢ val: 560 videos\n",
      "\n",
      "üîç Files Cell 15 needs:\n",
      "   ‚úÖ citizen_100_preprocessed.csv\n",
      "      Size: 411.14 KB\n",
      "   ‚úÖ label_mapping_100.json\n",
      "      Size: 4.89 KB\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ---------- VERIFY Cell 14 Output ----------\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"VERIFYING CELL 14 OUTPUT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check manifests directory\n",
    "manifests_dir = os.path.join(BASE_DIR, \"manifests\")\n",
    "print(f\"\\nüìÅ Manifests directory: {manifests_dir}\")\n",
    "print(f\"   Exists: {os.path.exists(manifests_dir)}\")\n",
    "\n",
    "if os.path.exists(manifests_dir):\n",
    "    print(\"\\nüìÑ Files in manifests:\")\n",
    "    for f in os.listdir(manifests_dir):\n",
    "        file_path = os.path.join(manifests_dir, f)\n",
    "        size_mb = os.path.getsize(file_path) / (1024**2)\n",
    "        print(f\"   ‚Ä¢ {f} ({size_mb:.2f} MB)\")\n",
    "\n",
    "# Check preprocessed directory\n",
    "preprocessed_dir = os.path.join(BASE_DIR, \"preprocessed_citizen_100\")\n",
    "print(f\"\\nüìÅ Preprocessed directory: {preprocessed_dir}\")\n",
    "print(f\"   Exists: {os.path.exists(preprocessed_dir)}\")\n",
    "\n",
    "if os.path.exists(preprocessed_dir):\n",
    "    for split in ['train', 'val']:\n",
    "        split_dir = os.path.join(preprocessed_dir, split)\n",
    "        if os.path.exists(split_dir):\n",
    "            count = len(list(Path(split_dir).glob(\"*.npz\")))\n",
    "            print(f\"   ‚Ä¢ {split}: {count} videos\")\n",
    "\n",
    "# Check specific files Cell 15 needs\n",
    "required_files = [\n",
    "    \"citizen_100_preprocessed.csv\",\n",
    "    \"label_mapping_100.json\"\n",
    "]\n",
    "\n",
    "print(\"\\nüîç Files Cell 15 needs:\")\n",
    "for req_file in required_files:\n",
    "    file_path = os.path.join(manifests_dir, req_file)\n",
    "    exists = os.path.exists(file_path)\n",
    "    status = \"‚úÖ\" if exists else \"‚ùå\"\n",
    "    print(f\"   {status} {req_file}\")\n",
    "    if exists:\n",
    "        size_kb = os.path.getsize(file_path) / 1024\n",
    "        print(f\"      Size: {size_kb:.2f} KB\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T10:35:23.684538Z",
     "iopub.status.busy": "2025-11-14T10:35:23.684049Z",
     "iopub.status.idle": "2025-11-14T10:35:23.709088Z",
     "shell.execute_reply": "2025-11-14T10:35:23.708339Z",
     "shell.execute_reply.started": "2025-11-14T10:35:23.684516Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CREATING CITIZEN 100 DATALOADERS\n",
      "============================================================\n",
      "\n",
      "‚úÖ Loaded Citizen 100: 2752 videos\n",
      "‚úÖ Classes: 100\n",
      "‚úÖ All 2752 videos successfully labeled\n",
      "\n",
      "üìä Split distribution:\n",
      "   ‚Ä¢ Train: 2192\n",
      "   ‚Ä¢ Val: 560\n",
      "\n",
      "============================================================\n",
      "Creating WLASLDataset:\n",
      "============================================================\n",
      "   ‚Ä¢ Total videos: 2192\n",
      "   ‚Ä¢ Augmentation: ENABLED (6 techniques)\n",
      "   ‚Ä¢ Unique glosses: 100\n",
      "   ‚Ä¢ Dataset sources:\n",
      "      - citizen: 2192 videos\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Creating WLASLDataset:\n",
      "============================================================\n",
      "   ‚Ä¢ Total videos: 560\n",
      "   ‚Ä¢ Augmentation: DISABLED\n",
      "   ‚Ä¢ Unique glosses: 100\n",
      "   ‚Ä¢ Dataset sources:\n",
      "      - citizen: 560 videos\n",
      "============================================================\n",
      "\n",
      "‚úÖ Created DataLoaders:\n",
      "   ‚Ä¢ Train: 274 batches\n",
      "   ‚Ä¢ Val: 70 batches\n",
      "\n",
      "‚úÖ Ready for Cell 16 - Train on Citizen 100\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ---------- Cell 15: Create Citizen 100 DataLoaders ----------\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CREATING CITIZEN 100 DATALOADERS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load preprocessed manifest\n",
    "citizen_prep_manifest = os.path.join(BASE_DIR, \"manifests\", \"citizen_100_preprocessed.csv\")\n",
    "df_citizen_100_prep = pd.read_csv(citizen_prep_manifest)\n",
    "\n",
    "# Load label mapping\n",
    "with open(os.path.join(BASE_DIR, \"manifests\", \"label_mapping_100.json\"), 'r') as f:\n",
    "    label_mapping_100 = json.load(f)\n",
    "    num_classes_100 = label_mapping_100['num_classes']\n",
    "    gloss_to_label = label_mapping_100['gloss_to_label']\n",
    "\n",
    "print(f\"\\n‚úÖ Loaded Citizen 100: {len(df_citizen_100_prep)} videos\")\n",
    "print(f\"‚úÖ Classes: {num_classes_100}\")\n",
    "\n",
    "# CRITICAL FIX: Add 'label' column using gloss_to_label mapping\n",
    "df_citizen_100_prep['label'] = df_citizen_100_prep['gloss'].map(gloss_to_label)\n",
    "\n",
    "# Verify all labels were mapped successfully\n",
    "if df_citizen_100_prep['label'].isna().any():\n",
    "    print(f\"\\n‚ö†Ô∏è WARNING: {df_citizen_100_prep['label'].isna().sum()} videos have missing labels!\")\n",
    "    missing_glosses = df_citizen_100_prep[df_citizen_100_prep['label'].isna()]['gloss'].unique()\n",
    "    print(f\"   Missing glosses: {missing_glosses}\")\n",
    "else:\n",
    "    print(f\"‚úÖ All {len(df_citizen_100_prep)} videos successfully labeled\")\n",
    "\n",
    "# Create splits (ONLY train and val - no test)\n",
    "train_df_100 = df_citizen_100_prep[df_citizen_100_prep['split'] == 'train'].copy()\n",
    "val_df_100 = df_citizen_100_prep[df_citizen_100_prep['split'] == 'val'].copy()\n",
    "\n",
    "print(\"\\nüìä Split distribution:\")\n",
    "print(f\"   ‚Ä¢ Train: {len(train_df_100)}\")\n",
    "print(f\"   ‚Ä¢ Val: {len(val_df_100)}\")\n",
    "\n",
    "# Create datasets (with improved augmentation!)\n",
    "train_dataset_100 = WLASLDataset(train_df_100, augment=True)\n",
    "val_dataset_100 = WLASLDataset(val_df_100, augment=False)\n",
    "\n",
    "# Create dataloaders\n",
    "BATCH_SIZE_100 = 8\n",
    "\n",
    "train_loader_100 = DataLoader(\n",
    "    train_dataset_100,\n",
    "    batch_size=BATCH_SIZE_100,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader_100 = DataLoader(\n",
    "    val_dataset_100,\n",
    "    batch_size=BATCH_SIZE_100,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Created DataLoaders:\")\n",
    "print(f\"   ‚Ä¢ Train: {len(train_loader_100)} batches\")\n",
    "print(f\"   ‚Ä¢ Val: {len(val_loader_100)} batches\")\n",
    "\n",
    "print(\"\\n‚úÖ Ready for Cell 16 - Train on Citizen 100\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T10:35:30.400814Z",
     "iopub.status.busy": "2025-11-14T10:35:30.400232Z",
     "iopub.status.idle": "2025-11-14T10:35:30.430242Z",
     "shell.execute_reply": "2025-11-14T10:35:30.429515Z",
     "shell.execute_reply.started": "2025-11-14T10:35:30.400788Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ I3D Model Architecture Loaded\n",
      "‚úÖ Module registered as CV.models.i3d for checkpoint loading\n"
     ]
    }
   ],
   "source": [
    "# ---------- I3D Model Architecture ----------\n",
    "# WLASL I3D implementation - needed for unpickling the saved model\n",
    "# This MUST be defined before loading the checkpoint\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class MaxPool3dSamePadding(nn.MaxPool3d):\n",
    "    def compute_pad(self, dim, s):\n",
    "        if s % self.stride[dim] == 0:\n",
    "            return max(self.kernel_size[dim] - self.stride[dim], 0)\n",
    "        else:\n",
    "            return max(self.kernel_size[dim] - (s % self.stride[dim]), 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        (batch, channel, t, h, w) = x.size()\n",
    "        pad_t = self.compute_pad(0, t)\n",
    "        pad_h = self.compute_pad(1, h)\n",
    "        pad_w = self.compute_pad(2, w)\n",
    "\n",
    "        pad_t_f = pad_t // 2\n",
    "        pad_t_b = pad_t - pad_t_f\n",
    "        pad_h_f = pad_h // 2\n",
    "        pad_h_b = pad_h - pad_h_f\n",
    "        pad_w_f = pad_w // 2\n",
    "        pad_w_b = pad_w - pad_w_f\n",
    "\n",
    "        pad = (pad_w_f, pad_w_b, pad_h_f, pad_h_b, pad_t_f, pad_t_b)\n",
    "        x = F.pad(x, pad)\n",
    "        return super(MaxPool3dSamePadding, self).forward(x)\n",
    "\n",
    "\n",
    "class Unit3D(nn.Module):\n",
    "    def __init__(self, in_channels, output_channels, kernel_shape=(1, 1, 1),\n",
    "                 stride=(1, 1, 1), padding=0, activation_fn=F.relu, use_batch_norm=True,\n",
    "                 use_bias=False, name='unit_3d'):\n",
    "        super(Unit3D, self).__init__()\n",
    "        \n",
    "        self._output_channels = output_channels\n",
    "        self._kernel_shape = kernel_shape\n",
    "        self._stride = stride\n",
    "        self._use_batch_norm = use_batch_norm\n",
    "        self._activation_fn = activation_fn\n",
    "        self._use_bias = use_bias\n",
    "        self.name = name\n",
    "        self.padding = padding\n",
    "        \n",
    "        self.conv3d = nn.Conv3d(in_channels=in_channels,\n",
    "                                out_channels=self._output_channels,\n",
    "                                kernel_size=self._kernel_shape,\n",
    "                                stride=self._stride,\n",
    "                                padding=0,\n",
    "                                bias=self._use_bias)\n",
    "        \n",
    "        if self._use_batch_norm:\n",
    "            self.bn = nn.BatchNorm3d(self._output_channels, eps=0.001, momentum=0.01)\n",
    "\n",
    "    def compute_pad(self, dim, s):\n",
    "        if s % self._stride[dim] == 0:\n",
    "            return max(self._kernel_shape[dim] - self._stride[dim], 0)\n",
    "        else:\n",
    "            return max(self._kernel_shape[dim] - (s % self._stride[dim]), 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        (batch, channel, t, h, w) = x.size()\n",
    "        pad_t = self.compute_pad(0, t)\n",
    "        pad_h = self.compute_pad(1, h)\n",
    "        pad_w = self.compute_pad(2, w)\n",
    "\n",
    "        pad_t_f = pad_t // 2\n",
    "        pad_t_b = pad_t - pad_t_f\n",
    "        pad_h_f = pad_h // 2\n",
    "        pad_h_b = pad_h - pad_h_f\n",
    "        pad_w_f = pad_w // 2\n",
    "        pad_w_b = pad_w - pad_w_f\n",
    "\n",
    "        pad = (pad_w_f, pad_w_b, pad_h_f, pad_h_b, pad_t_f, pad_t_b)\n",
    "        x = F.pad(x, pad)\n",
    "        \n",
    "        x = self.conv3d(x)\n",
    "        if self._use_batch_norm:\n",
    "            x = self.bn(x)\n",
    "        if self._activation_fn is not None:\n",
    "            x = self._activation_fn(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class InceptionModule(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, name):\n",
    "        super(InceptionModule, self).__init__()\n",
    "\n",
    "        self.b0 = Unit3D(in_channels=in_channels, output_channels=out_channels[0],\n",
    "                         kernel_shape=[1, 1, 1], padding=0, name=name+'/Branch_0/Conv3d_0a_1x1')\n",
    "        self.b1a = Unit3D(in_channels=in_channels, output_channels=out_channels[1],\n",
    "                          kernel_shape=[1, 1, 1], padding=0, name=name+'/Branch_1/Conv3d_0a_1x1')\n",
    "        self.b1b = Unit3D(in_channels=out_channels[1], output_channels=out_channels[2],\n",
    "                          kernel_shape=[3, 3, 3], name=name+'/Branch_1/Conv3d_0b_3x3')\n",
    "        self.b2a = Unit3D(in_channels=in_channels, output_channels=out_channels[3],\n",
    "                          kernel_shape=[1, 1, 1], padding=0, name=name+'/Branch_2/Conv3d_0a_1x1')\n",
    "        self.b2b = Unit3D(in_channels=out_channels[3], output_channels=out_channels[4],\n",
    "                          kernel_shape=[3, 3, 3], name=name+'/Branch_2/Conv3d_0b_3x3')\n",
    "        self.b3a = MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=0)\n",
    "        self.b3b = Unit3D(in_channels=in_channels, output_channels=out_channels[5],\n",
    "                          kernel_shape=[1, 1, 1], padding=0, name=name+'/Branch_3/Conv3d_0b_1x1')\n",
    "        self.name = name\n",
    "\n",
    "    def forward(self, x):\n",
    "        b0 = self.b0(x)\n",
    "        b1 = self.b1b(self.b1a(x))\n",
    "        b2 = self.b2b(self.b2a(x))\n",
    "        b3 = self.b3b(self.b3a(x))\n",
    "        return torch.cat([b0, b1, b2, b3], dim=1)\n",
    "\n",
    "\n",
    "class InceptionI3d(nn.Module):\n",
    "    \"\"\"Inception-v1 I3D architecture.\"\"\"\n",
    "\n",
    "    def __init__(self, num_classes=400, spatial_squeeze=True,\n",
    "                 final_endpoint='Logits', name='inception_i3d', in_channels=3, dropout_keep_prob=0.5):\n",
    "        super(InceptionI3d, self).__init__()\n",
    "\n",
    "        self._num_classes = num_classes\n",
    "        self._spatial_squeeze = spatial_squeeze\n",
    "        self._final_endpoint = final_endpoint\n",
    "        self.logits = None\n",
    "\n",
    "        if self._final_endpoint not in ['Conv3d_1a_7x7', 'MaxPool3d_2a_3x3', 'Conv3d_2b_1x1', 'Conv3d_2c_3x3',\n",
    "                                          'MaxPool3d_3a_3x3', 'Mixed_3b', 'Mixed_3c', 'MaxPool3d_4a_3x3',\n",
    "                                          'Mixed_4b', 'Mixed_4c', 'Mixed_4d', 'Mixed_4e', 'Mixed_4f',\n",
    "                                          'MaxPool3d_5a_2x2', 'Mixed_5b', 'Mixed_5c', 'Logits', 'Predictions']:\n",
    "            raise ValueError('Unknown final endpoint %s' % self._final_endpoint)\n",
    "\n",
    "        # Build network\n",
    "        self.end_points = {}\n",
    "        end_point = 'Conv3d_1a_7x7'\n",
    "        self.end_points[end_point] = Unit3D(in_channels=in_channels, output_channels=64, kernel_shape=[7, 7, 7],\n",
    "                                             stride=(2, 2, 2), padding=(3,3,3),  name=end_point)\n",
    "        if self._final_endpoint == end_point: return\n",
    "\n",
    "        end_point = 'MaxPool3d_2a_3x3'\n",
    "        self.end_points[end_point] = MaxPool3dSamePadding(kernel_size=[1, 3, 3], stride=(1, 2, 2), padding=0)\n",
    "        if self._final_endpoint == end_point: return\n",
    "\n",
    "        end_point = 'Conv3d_2b_1x1'\n",
    "        self.end_points[end_point] = Unit3D(in_channels=64, output_channels=64, kernel_shape=[1, 1, 1], padding=0,\n",
    "                                             name=end_point)\n",
    "        if self._final_endpoint == end_point: return\n",
    "\n",
    "        end_point = 'Conv3d_2c_3x3'\n",
    "        self.end_points[end_point] = Unit3D(in_channels=64, output_channels=192, kernel_shape=[3, 3, 3], padding=1,\n",
    "                                             name=end_point)\n",
    "        if self._final_endpoint == end_point: return\n",
    "\n",
    "        end_point = 'MaxPool3d_3a_3x3'\n",
    "        self.end_points[end_point] = MaxPool3dSamePadding(kernel_size=[1, 3, 3], stride=(1, 2, 2), padding=0)\n",
    "        if self._final_endpoint == end_point: return\n",
    "\n",
    "        end_point = 'Mixed_3b'\n",
    "        self.end_points[end_point] = InceptionModule(192, [64, 96, 128, 16, 32, 32], name=end_point)\n",
    "        if self._final_endpoint == end_point: return\n",
    "\n",
    "        end_point = 'Mixed_3c'\n",
    "        self.end_points[end_point] = InceptionModule(256, [128, 128, 192, 32, 96, 64], name=end_point)\n",
    "        if self._final_endpoint == end_point: return\n",
    "\n",
    "        end_point = 'MaxPool3d_4a_3x3'\n",
    "        self.end_points[end_point] = MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(2, 2, 2), padding=0)\n",
    "        if self._final_endpoint == end_point: return\n",
    "\n",
    "        end_point = 'Mixed_4b'\n",
    "        self.end_points[end_point] = InceptionModule(128+192+96+64, [192, 96, 208, 16, 48, 64], name=end_point)\n",
    "        if self._final_endpoint == end_point: return\n",
    "\n",
    "        end_point = 'Mixed_4c'\n",
    "        self.end_points[end_point] = InceptionModule(192+208+48+64, [160, 112, 224, 24, 64, 64], name=end_point)\n",
    "        if self._final_endpoint == end_point: return\n",
    "\n",
    "        end_point = 'Mixed_4d'\n",
    "        self.end_points[end_point] = InceptionModule(160+224+64+64, [128, 128, 256, 24, 64, 64], name=end_point)\n",
    "        if self._final_endpoint == end_point: return\n",
    "\n",
    "        end_point = 'Mixed_4e'\n",
    "        self.end_points[end_point] = InceptionModule(128+256+64+64, [112, 144, 288, 32, 64, 64], name=end_point)\n",
    "        if self._final_endpoint == end_point: return\n",
    "\n",
    "        end_point = 'Mixed_4f'\n",
    "        self.end_points[end_point] = InceptionModule(112+288+64+64, [256, 160, 320, 32, 128, 128], name=end_point)\n",
    "        if self._final_endpoint == end_point: return\n",
    "\n",
    "        end_point = 'MaxPool3d_5a_2x2'\n",
    "        self.end_points[end_point] = MaxPool3dSamePadding(kernel_size=[2, 2, 2], stride=(2, 2, 2), padding=0)\n",
    "        if self._final_endpoint == end_point: return\n",
    "\n",
    "        end_point = 'Mixed_5b'\n",
    "        self.end_points[end_point] = InceptionModule(256+320+128+128, [256, 160, 320, 32, 128, 128], name=end_point)\n",
    "        if self._final_endpoint == end_point: return\n",
    "\n",
    "        end_point = 'Mixed_5c'\n",
    "        self.end_points[end_point] = InceptionModule(256+320+128+128, [384, 192, 384, 48, 128, 128], name=end_point)\n",
    "        if self._final_endpoint == end_point: return\n",
    "\n",
    "        end_point = 'Logits'\n",
    "        self.avg_pool = nn.AvgPool3d(kernel_size=[2, 7, 7], stride=(1, 1, 1))\n",
    "        self.dropout = nn.Dropout(dropout_keep_prob)\n",
    "        self.logits = Unit3D(in_channels=384+384+128+128, output_channels=self._num_classes,\n",
    "                             kernel_shape=[1, 1, 1],\n",
    "                             padding=0,\n",
    "                             activation_fn=None,\n",
    "                             use_batch_norm=False,\n",
    "                             use_bias=True,\n",
    "                             name='logits')\n",
    "\n",
    "        self.build()\n",
    "\n",
    "    def replace_logits(self, num_classes):\n",
    "        self._num_classes = num_classes\n",
    "        self.logits = Unit3D(in_channels=384+384+128+128, output_channels=self._num_classes,\n",
    "                             kernel_shape=[1, 1, 1],\n",
    "                             padding=0,\n",
    "                             activation_fn=None,\n",
    "                             use_batch_norm=False,\n",
    "                             use_bias=True,\n",
    "                             name='logits')\n",
    "\n",
    "    def build(self):\n",
    "        for k in self.end_points.keys():\n",
    "            self.add_module(k, self.end_points[k])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for end_point in self.end_points:\n",
    "            if end_point in self.end_points:\n",
    "                x = self._modules[end_point](x)\n",
    "\n",
    "        x = self.logits(self.dropout(self.avg_pool(x)))\n",
    "        if self._spatial_squeeze:\n",
    "            x = x.squeeze(3).squeeze(3)\n",
    "        \n",
    "        x = x.mean(2)\n",
    "        return x\n",
    "\n",
    "# Register the classes in sys.modules so PyTorch can find them when unpickling\n",
    "# The checkpoint was saved with CV.models.i3d namespace\n",
    "import sys\n",
    "from types import ModuleType\n",
    "\n",
    "# Create dummy module structure\n",
    "CV = ModuleType('CV')\n",
    "CV_models = ModuleType('CV.models')\n",
    "CV_models_i3d = ModuleType('CV.models.i3d')\n",
    "\n",
    "# Add our I3D classes to the fake module\n",
    "CV_models_i3d.MaxPool3dSamePadding = MaxPool3dSamePadding\n",
    "CV_models_i3d.Unit3D = Unit3D\n",
    "CV_models_i3d.InceptionModule = InceptionModule\n",
    "CV_models_i3d.InceptionI3d = InceptionI3d\n",
    "\n",
    "# Register in sys.modules\n",
    "sys.modules['CV'] = CV\n",
    "sys.modules['CV.models'] = CV_models\n",
    "sys.modules['CV.models.i3d'] = CV_models_i3d\n",
    "\n",
    "print(\"‚úÖ I3D Model Architecture Loaded\")\n",
    "print(\"‚úÖ Module registered as CV.models.i3d for checkpoint loading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T10:35:44.723657Z",
     "iopub.status.busy": "2025-11-14T10:35:44.723093Z",
     "iopub.status.idle": "2025-11-14T14:04:05.114216Z",
     "shell.execute_reply": "2025-11-14T14:04:05.113293Z",
     "shell.execute_reply.started": "2025-11-14T10:35:44.723634Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRAINING ON CITIZEN 100 LABELS\n",
      "============================================================\n",
      "‚úÖ Loading FULL checkpoint: /kaggle/working/WASL/models/checkpoints/best_model_FULL.pth\n",
      "   (Contains complete I3D model with architecture + weights)\n",
      "\n",
      "üì¶ Checkpoint contents:\n",
      "   ‚Ä¢ model\n",
      "   ‚Ä¢ val_acc\n",
      "   ‚Ä¢ epoch\n",
      "   ‚Ä¢ train_loss\n",
      "   ‚Ä¢ train_acc\n",
      "   ‚Ä¢ val_loss\n",
      "   ‚Ä¢ history\n",
      "\n",
      "‚úÖ Loaded FULL model object!\n",
      "   ‚Ä¢ Model type: InceptionI3d\n",
      "   ‚Ä¢ Validation accuracy: 75.15%\n",
      "   ‚Ä¢ Classes: 100\n",
      "\n",
      "‚úÖ Model moved to: cuda\n",
      "   ‚Ä¢ Ready to train on Citizen 100!\n",
      "\n",
      "üìã Training configuration:\n",
      "   ‚Ä¢ num_epochs: 50\n",
      "   ‚Ä¢ learning_rate: 0.0001\n",
      "   ‚Ä¢ weight_decay: 1e-08\n",
      "   ‚Ä¢ adam_eps: 0.001\n",
      "   ‚Ä¢ patience: 10\n",
      "   ‚Ä¢ grad_clip: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STARTING TRAINING\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:48<00:00,  1.20it/s, loss=3.2499, acc=35.45%]\n",
      "Epoch 1/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:22<00:00,  3.05it/s, loss=2.9058, acc=46.25%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 1/50:\n",
      "============================================================\n",
      "Train Loss: 2.8318 | Train Acc: 35.45%\n",
      "Val Loss:   2.0787 | Val Acc:   46.25%\n",
      "Learning Rate: 0.000100\n",
      "Time: 251.0s | Total: 4.2min\n",
      "‚úÖ New best model saved! Val acc: 46.25%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:47<00:00,  1.20it/s, loss=2.5946, acc=50.41%]\n",
      "Epoch 2/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:23<00:00,  3.03it/s, loss=2.1401, acc=59.64%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 2/50:\n",
      "============================================================\n",
      "Train Loss: 2.1128 | Train Acc: 50.41%\n",
      "Val Loss:   1.5362 | Val Acc:   59.64%\n",
      "Learning Rate: 0.000100\n",
      "Time: 251.1s | Total: 8.4min\n",
      "‚úÖ New best model saved! Val acc: 59.64%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:48<00:00,  1.20it/s, loss=2.1010, acc=58.35%]\n",
      "Epoch 3/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:22<00:00,  3.07it/s, loss=1.3801, acc=66.43%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 3/50:\n",
      "============================================================\n",
      "Train Loss: 1.7176 | Train Acc: 58.35%\n",
      "Val Loss:   1.2752 | Val Acc:   66.43%\n",
      "Learning Rate: 0.000100\n",
      "Time: 251.5s | Total: 12.6min\n",
      "‚úÖ New best model saved! Val acc: 66.43%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:43<00:00,  1.22it/s, loss=1.3566, acc=66.38%]\n",
      "Epoch 4/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:22<00:00,  3.08it/s, loss=1.1442, acc=70.18%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 4/50:\n",
      "============================================================\n",
      "Train Loss: 1.4109 | Train Acc: 66.38%\n",
      "Val Loss:   1.0561 | Val Acc:   70.18%\n",
      "Learning Rate: 0.000100\n",
      "Time: 246.6s | Total: 16.7min\n",
      "‚úÖ New best model saved! Val acc: 70.18%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:44<00:00,  1.22it/s, loss=0.6068, acc=70.71%]\n",
      "Epoch 5/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:22<00:00,  3.10it/s, loss=1.1868, acc=73.75%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 5/50:\n",
      "============================================================\n",
      "Train Loss: 1.2130 | Train Acc: 70.71%\n",
      "Val Loss:   0.9464 | Val Acc:   73.75%\n",
      "Learning Rate: 0.000100\n",
      "Time: 247.4s | Total: 20.8min\n",
      "‚úÖ New best model saved! Val acc: 73.75%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:49<00:00,  1.20it/s, loss=1.0778, acc=76.64%]\n",
      "Epoch 6/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:22<00:00,  3.09it/s, loss=0.9747, acc=77.68%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 6/50:\n",
      "============================================================\n",
      "Train Loss: 1.0312 | Train Acc: 76.64%\n",
      "Val Loss:   0.8519 | Val Acc:   77.68%\n",
      "Learning Rate: 0.000100\n",
      "Time: 251.9s | Total: 25.0min\n",
      "‚úÖ New best model saved! Val acc: 77.68%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:46<00:00,  1.21it/s, loss=0.3352, acc=79.24%]\n",
      "Epoch 7/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:22<00:00,  3.07it/s, loss=0.9116, acc=78.04%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 7/50:\n",
      "============================================================\n",
      "Train Loss: 0.8798 | Train Acc: 79.24%\n",
      "Val Loss:   0.7809 | Val Acc:   78.04%\n",
      "Learning Rate: 0.000100\n",
      "Time: 249.2s | Total: 29.2min\n",
      "‚úÖ New best model saved! Val acc: 78.04%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:48<00:00,  1.20it/s, loss=0.2656, acc=82.07%]\n",
      "Epoch 8/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:22<00:00,  3.07it/s, loss=0.7904, acc=79.29%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 8/50:\n",
      "============================================================\n",
      "Train Loss: 0.7734 | Train Acc: 82.07%\n",
      "Val Loss:   0.7244 | Val Acc:   79.29%\n",
      "Learning Rate: 0.000100\n",
      "Time: 250.9s | Total: 33.4min\n",
      "‚úÖ New best model saved! Val acc: 79.29%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:45<00:00,  1.21it/s, loss=0.8334, acc=84.58%]\n",
      "Epoch 9/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:22<00:00,  3.08it/s, loss=0.7459, acc=80.71%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 9/50:\n",
      "============================================================\n",
      "Train Loss: 0.6884 | Train Acc: 84.58%\n",
      "Val Loss:   0.6930 | Val Acc:   80.71%\n",
      "Learning Rate: 0.000100\n",
      "Time: 248.4s | Total: 37.5min\n",
      "‚úÖ New best model saved! Val acc: 80.71%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:46<00:00,  1.21it/s, loss=0.4962, acc=87.09%]\n",
      "Epoch 10/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:22<00:00,  3.05it/s, loss=0.8757, acc=80.00%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 10/50:\n",
      "============================================================\n",
      "Train Loss: 0.6028 | Train Acc: 87.09%\n",
      "Val Loss:   0.6792 | Val Acc:   80.00%\n",
      "Learning Rate: 0.000100\n",
      "Time: 249.2s | Total: 41.7min\n",
      "‚è≥ Patience: 1/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:50<00:00,  1.19it/s, loss=0.3849, acc=87.59%]\n",
      "Epoch 11/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:22<00:00,  3.10it/s, loss=0.6377, acc=82.32%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 11/50:\n",
      "============================================================\n",
      "Train Loss: 0.5292 | Train Acc: 87.59%\n",
      "Val Loss:   0.6255 | Val Acc:   82.32%\n",
      "Learning Rate: 0.000100\n",
      "Time: 253.3s | Total: 45.9min\n",
      "‚úÖ New best model saved! Val acc: 82.32%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:44<00:00,  1.22it/s, loss=0.6928, acc=89.96%]\n",
      "Epoch 12/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:22<00:00,  3.08it/s, loss=0.6828, acc=83.75%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 12/50:\n",
      "============================================================\n",
      "Train Loss: 0.4767 | Train Acc: 89.96%\n",
      "Val Loss:   0.5932 | Val Acc:   83.75%\n",
      "Learning Rate: 0.000100\n",
      "Time: 247.6s | Total: 50.0min\n",
      "‚úÖ New best model saved! Val acc: 83.75%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:51<00:00,  1.18it/s, loss=0.4397, acc=91.20%]\n",
      "Epoch 13/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:22<00:00,  3.06it/s, loss=0.4956, acc=83.21%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 13/50:\n",
      "============================================================\n",
      "Train Loss: 0.4085 | Train Acc: 91.20%\n",
      "Val Loss:   0.6083 | Val Acc:   83.21%\n",
      "Learning Rate: 0.000100\n",
      "Time: 254.4s | Total: 54.3min\n",
      "‚è≥ Patience: 1/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:50<00:00,  1.19it/s, loss=0.5955, acc=91.10%]\n",
      "Epoch 14/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:23<00:00,  3.03it/s, loss=0.5065, acc=84.82%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 14/50:\n",
      "============================================================\n",
      "Train Loss: 0.3955 | Train Acc: 91.10%\n",
      "Val Loss:   0.5487 | Val Acc:   84.82%\n",
      "Learning Rate: 0.000100\n",
      "Time: 253.7s | Total: 58.5min\n",
      "‚úÖ New best model saved! Val acc: 84.82%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:47<00:00,  1.20it/s, loss=0.4110, acc=92.47%]\n",
      "Epoch 15/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:22<00:00,  3.07it/s, loss=0.4116, acc=84.82%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 15/50:\n",
      "============================================================\n",
      "Train Loss: 0.3368 | Train Acc: 92.47%\n",
      "Val Loss:   0.5284 | Val Acc:   84.82%\n",
      "Learning Rate: 0.000100\n",
      "Time: 250.7s | Total: 62.7min\n",
      "‚è≥ Patience: 1/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:48<00:00,  1.20it/s, loss=0.2153, acc=92.93%]\n",
      "Epoch 16/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:22<00:00,  3.08it/s, loss=0.6145, acc=85.71%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 16/50:\n",
      "============================================================\n",
      "Train Loss: 0.3079 | Train Acc: 92.93%\n",
      "Val Loss:   0.5266 | Val Acc:   85.71%\n",
      "Learning Rate: 0.000100\n",
      "Time: 251.1s | Total: 66.9min\n",
      "‚úÖ New best model saved! Val acc: 85.71%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:49<00:00,  1.19it/s, loss=0.1137, acc=93.98%]\n",
      "Epoch 17/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:22<00:00,  3.09it/s, loss=0.6122, acc=84.82%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 17/50:\n",
      "============================================================\n",
      "Train Loss: 0.2816 | Train Acc: 93.98%\n",
      "Val Loss:   0.5541 | Val Acc:   84.82%\n",
      "Learning Rate: 0.000100\n",
      "Time: 252.6s | Total: 71.1min\n",
      "‚è≥ Patience: 1/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:49<00:00,  1.19it/s, loss=0.0608, acc=94.98%]\n",
      "Epoch 18/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:23<00:00,  3.03it/s, loss=0.6184, acc=83.21%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 18/50:\n",
      "============================================================\n",
      "Train Loss: 0.2466 | Train Acc: 94.98%\n",
      "Val Loss:   0.5526 | Val Acc:   83.21%\n",
      "Learning Rate: 0.000100\n",
      "Time: 252.4s | Total: 75.3min\n",
      "‚è≥ Patience: 2/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:47<00:00,  1.20it/s, loss=0.0470, acc=95.39%]\n",
      "Epoch 19/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:22<00:00,  3.05it/s, loss=0.5005, acc=85.18%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 19/50:\n",
      "============================================================\n",
      "Train Loss: 0.2182 | Train Acc: 95.39%\n",
      "Val Loss:   0.5313 | Val Acc:   85.18%\n",
      "Learning Rate: 0.000100\n",
      "Time: 250.6s | Total: 79.5min\n",
      "‚è≥ Patience: 3/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:48<00:00,  1.20it/s, loss=0.0532, acc=95.85%]\n",
      "Epoch 20/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:22<00:00,  3.07it/s, loss=0.5248, acc=83.93%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 20/50:\n",
      "============================================================\n",
      "Train Loss: 0.1894 | Train Acc: 95.85%\n",
      "Val Loss:   0.5569 | Val Acc:   83.93%\n",
      "Learning Rate: 0.000100\n",
      "Time: 251.8s | Total: 83.7min\n",
      "‚è≥ Patience: 4/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:46<00:00,  1.21it/s, loss=0.1355, acc=96.94%]\n",
      "Epoch 21/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:22<00:00,  3.09it/s, loss=0.3448, acc=85.36%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 21/50:\n",
      "============================================================\n",
      "Train Loss: 0.1658 | Train Acc: 96.94%\n",
      "Val Loss:   0.5234 | Val Acc:   85.36%\n",
      "Learning Rate: 0.000100\n",
      "Time: 249.3s | Total: 87.8min\n",
      "‚è≥ Patience: 5/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:46<00:00,  1.21it/s, loss=0.0201, acc=97.08%]\n",
      "Epoch 22/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:22<00:00,  3.11it/s, loss=0.2390, acc=85.00%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 22/50:\n",
      "============================================================\n",
      "Train Loss: 0.1525 | Train Acc: 97.08%\n",
      "Val Loss:   0.5007 | Val Acc:   85.00%\n",
      "Learning Rate: 0.000100\n",
      "Time: 249.4s | Total: 92.0min\n",
      "‚è≥ Patience: 6/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:48<00:00,  1.20it/s, loss=0.0851, acc=97.13%]\n",
      "Epoch 23/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:23<00:00,  3.04it/s, loss=0.4539, acc=86.25%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 23/50:\n",
      "============================================================\n",
      "Train Loss: 0.1382 | Train Acc: 97.13%\n",
      "Val Loss:   0.5131 | Val Acc:   86.25%\n",
      "Learning Rate: 0.000100\n",
      "Time: 251.1s | Total: 96.2min\n",
      "‚úÖ New best model saved! Val acc: 86.25%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:47<00:00,  1.20it/s, loss=0.1448, acc=97.31%]\n",
      "Epoch 24/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:23<00:00,  3.04it/s, loss=0.6382, acc=84.82%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 24/50:\n",
      "============================================================\n",
      "Train Loss: 0.1230 | Train Acc: 97.31%\n",
      "Val Loss:   0.5396 | Val Acc:   84.82%\n",
      "Learning Rate: 0.000100\n",
      "Time: 250.8s | Total: 100.4min\n",
      "‚è≥ Patience: 1/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:46<00:00,  1.21it/s, loss=0.1872, acc=98.04%]\n",
      "Epoch 25/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:22<00:00,  3.12it/s, loss=0.4000, acc=86.43%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 25/50:\n",
      "============================================================\n",
      "Train Loss: 0.1082 | Train Acc: 98.04%\n",
      "Val Loss:   0.5088 | Val Acc:   86.43%\n",
      "Learning Rate: 0.000100\n",
      "Time: 248.8s | Total: 104.5min\n",
      "‚úÖ New best model saved! Val acc: 86.43%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:44<00:00,  1.22it/s, loss=0.1337, acc=97.67%]\n",
      "Epoch 26/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:22<00:00,  3.07it/s, loss=0.5886, acc=87.14%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 26/50:\n",
      "============================================================\n",
      "Train Loss: 0.1052 | Train Acc: 97.67%\n",
      "Val Loss:   0.5204 | Val Acc:   87.14%\n",
      "Learning Rate: 0.000100\n",
      "Time: 247.2s | Total: 108.6min\n",
      "‚úÖ New best model saved! Val acc: 87.14%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:43<00:00,  1.23it/s, loss=0.0065, acc=97.99%]\n",
      "Epoch 27/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:23<00:00,  3.02it/s, loss=0.5678, acc=85.00%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 27/50:\n",
      "============================================================\n",
      "Train Loss: 0.1010 | Train Acc: 97.99%\n",
      "Val Loss:   0.5614 | Val Acc:   85.00%\n",
      "Learning Rate: 0.000100\n",
      "Time: 246.5s | Total: 112.7min\n",
      "‚è≥ Patience: 1/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:48<00:00,  1.20it/s, loss=0.0851, acc=98.40%]\n",
      "Epoch 28/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:22<00:00,  3.08it/s, loss=0.4465, acc=86.61%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 28/50:\n",
      "============================================================\n",
      "Train Loss: 0.0848 | Train Acc: 98.40%\n",
      "Val Loss:   0.5209 | Val Acc:   86.61%\n",
      "Learning Rate: 0.000050\n",
      "Time: 251.4s | Total: 116.9min\n",
      "‚è≥ Patience: 2/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:47<00:00,  1.20it/s, loss=0.3476, acc=98.45%]\n",
      "Epoch 29/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:22<00:00,  3.10it/s, loss=0.3031, acc=87.14%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 29/50:\n",
      "============================================================\n",
      "Train Loss: 0.0754 | Train Acc: 98.45%\n",
      "Val Loss:   0.5143 | Val Acc:   87.14%\n",
      "Learning Rate: 0.000050\n",
      "Time: 250.3s | Total: 121.1min\n",
      "‚è≥ Patience: 3/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:46<00:00,  1.21it/s, loss=0.0350, acc=98.40%]\n",
      "Epoch 30/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:22<00:00,  3.12it/s, loss=0.2500, acc=86.43%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 30/50:\n",
      "============================================================\n",
      "Train Loss: 0.0717 | Train Acc: 98.40%\n",
      "Val Loss:   0.5340 | Val Acc:   86.43%\n",
      "Learning Rate: 0.000050\n",
      "Time: 248.8s | Total: 125.2min\n",
      "‚è≥ Patience: 4/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:42<00:00,  1.23it/s, loss=0.0148, acc=98.91%]\n",
      "Epoch 31/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:22<00:00,  3.08it/s, loss=0.2130, acc=87.32%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 31/50:\n",
      "============================================================\n",
      "Train Loss: 0.0591 | Train Acc: 98.91%\n",
      "Val Loss:   0.5281 | Val Acc:   87.32%\n",
      "Learning Rate: 0.000050\n",
      "Time: 245.5s | Total: 129.3min\n",
      "‚úÖ New best model saved! Val acc: 87.32%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:44<00:00,  1.22it/s, loss=0.0060, acc=98.45%]\n",
      "Epoch 32/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:22<00:00,  3.06it/s, loss=0.2607, acc=86.61%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 32/50:\n",
      "============================================================\n",
      "Train Loss: 0.0684 | Train Acc: 98.45%\n",
      "Val Loss:   0.5275 | Val Acc:   86.61%\n",
      "Learning Rate: 0.000050\n",
      "Time: 247.6s | Total: 133.5min\n",
      "‚è≥ Patience: 1/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:45<00:00,  1.21it/s, loss=0.0185, acc=98.95%]\n",
      "Epoch 33/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:23<00:00,  3.04it/s, loss=0.2053, acc=87.32%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 33/50:\n",
      "============================================================\n",
      "Train Loss: 0.0542 | Train Acc: 98.95%\n",
      "Val Loss:   0.5145 | Val Acc:   87.32%\n",
      "Learning Rate: 0.000050\n",
      "Time: 249.0s | Total: 137.6min\n",
      "‚è≥ Patience: 2/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:47<00:00,  1.20it/s, loss=0.0297, acc=99.09%]\n",
      "Epoch 34/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:22<00:00,  3.10it/s, loss=0.1552, acc=87.50%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 34/50:\n",
      "============================================================\n",
      "Train Loss: 0.0525 | Train Acc: 99.09%\n",
      "Val Loss:   0.5156 | Val Acc:   87.50%\n",
      "Learning Rate: 0.000025\n",
      "Time: 250.6s | Total: 141.8min\n",
      "‚úÖ New best model saved! Val acc: 87.50%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:47<00:00,  1.21it/s, loss=0.3577, acc=98.81%]\n",
      "Epoch 35/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:23<00:00,  3.02it/s, loss=0.2357, acc=86.79%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 35/50:\n",
      "============================================================\n",
      "Train Loss: 0.0561 | Train Acc: 98.81%\n",
      "Val Loss:   0.5186 | Val Acc:   86.79%\n",
      "Learning Rate: 0.000025\n",
      "Time: 250.5s | Total: 146.0min\n",
      "‚è≥ Patience: 1/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:45<00:00,  1.22it/s, loss=0.0122, acc=99.32%]\n",
      "Epoch 36/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:22<00:00,  3.05it/s, loss=0.2078, acc=86.43%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 36/50:\n",
      "============================================================\n",
      "Train Loss: 0.0480 | Train Acc: 99.32%\n",
      "Val Loss:   0.5183 | Val Acc:   86.43%\n",
      "Learning Rate: 0.000025\n",
      "Time: 248.0s | Total: 150.1min\n",
      "‚è≥ Patience: 2/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:48<00:00,  1.20it/s, loss=0.0185, acc=99.09%]\n",
      "Epoch 37/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:22<00:00,  3.06it/s, loss=0.2767, acc=86.96%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 37/50:\n",
      "============================================================\n",
      "Train Loss: 0.0404 | Train Acc: 99.09%\n",
      "Val Loss:   0.5222 | Val Acc:   86.96%\n",
      "Learning Rate: 0.000025\n",
      "Time: 251.1s | Total: 154.3min\n",
      "‚è≥ Patience: 3/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:50<00:00,  1.19it/s, loss=0.0087, acc=99.22%]\n",
      "Epoch 38/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:22<00:00,  3.05it/s, loss=0.2937, acc=86.96%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 38/50:\n",
      "============================================================\n",
      "Train Loss: 0.0443 | Train Acc: 99.22%\n",
      "Val Loss:   0.5039 | Val Acc:   86.96%\n",
      "Learning Rate: 0.000025\n",
      "Time: 253.9s | Total: 158.5min\n",
      "‚è≥ Patience: 4/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:47<00:00,  1.21it/s, loss=0.0076, acc=99.13%]\n",
      "Epoch 39/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:22<00:00,  3.10it/s, loss=0.2729, acc=86.79%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 39/50:\n",
      "============================================================\n",
      "Train Loss: 0.0444 | Train Acc: 99.13%\n",
      "Val Loss:   0.5136 | Val Acc:   86.79%\n",
      "Learning Rate: 0.000025\n",
      "Time: 250.0s | Total: 162.7min\n",
      "‚è≥ Patience: 5/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:50<00:00,  1.19it/s, loss=0.0110, acc=99.13%]\n",
      "Epoch 40/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:22<00:00,  3.10it/s, loss=0.3249, acc=86.61%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 40/50:\n",
      "============================================================\n",
      "Train Loss: 0.0433 | Train Acc: 99.13%\n",
      "Val Loss:   0.5081 | Val Acc:   86.61%\n",
      "Learning Rate: 0.000013\n",
      "Time: 253.0s | Total: 166.9min\n",
      "‚è≥ Patience: 6/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:48<00:00,  1.20it/s, loss=0.0079, acc=99.54%]\n",
      "Epoch 41/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:22<00:00,  3.08it/s, loss=0.2300, acc=86.96%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 41/50:\n",
      "============================================================\n",
      "Train Loss: 0.0375 | Train Acc: 99.54%\n",
      "Val Loss:   0.5034 | Val Acc:   86.96%\n",
      "Learning Rate: 0.000013\n",
      "Time: 251.2s | Total: 171.1min\n",
      "‚è≥ Patience: 7/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:42<00:00,  1.23it/s, loss=0.0179, acc=99.18%]\n",
      "Epoch 42/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:22<00:00,  3.08it/s, loss=0.2282, acc=86.25%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 42/50:\n",
      "============================================================\n",
      "Train Loss: 0.0415 | Train Acc: 99.18%\n",
      "Val Loss:   0.5079 | Val Acc:   86.25%\n",
      "Learning Rate: 0.000013\n",
      "Time: 245.2s | Total: 175.2min\n",
      "‚è≥ Patience: 8/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:41<00:00,  1.24it/s, loss=0.0075, acc=99.18%]\n",
      "Epoch 43/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:22<00:00,  3.08it/s, loss=0.2149, acc=86.43%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 43/50:\n",
      "============================================================\n",
      "Train Loss: 0.0450 | Train Acc: 99.18%\n",
      "Val Loss:   0.5017 | Val Acc:   86.43%\n",
      "Learning Rate: 0.000013\n",
      "Time: 244.3s | Total: 179.3min\n",
      "‚è≥ Patience: 9/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:41<00:00,  1.24it/s, loss=0.0636, acc=99.41%]\n",
      "Epoch 44/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:23<00:00,  3.02it/s, loss=0.2173, acc=87.68%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 44/50:\n",
      "============================================================\n",
      "Train Loss: 0.0382 | Train Acc: 99.41%\n",
      "Val Loss:   0.4974 | Val Acc:   87.68%\n",
      "Learning Rate: 0.000013\n",
      "Time: 244.3s | Total: 183.3min\n",
      "‚úÖ New best model saved! Val acc: 87.68%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:50<00:00,  1.19it/s, loss=0.0159, acc=99.32%]\n",
      "Epoch 45/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:22<00:00,  3.09it/s, loss=0.2431, acc=87.50%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 45/50:\n",
      "============================================================\n",
      "Train Loss: 0.0416 | Train Acc: 99.32%\n",
      "Val Loss:   0.5028 | Val Acc:   87.50%\n",
      "Learning Rate: 0.000013\n",
      "Time: 253.5s | Total: 187.6min\n",
      "‚è≥ Patience: 1/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:44<00:00,  1.22it/s, loss=0.0338, acc=99.50%]\n",
      "Epoch 46/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:22<00:00,  3.12it/s, loss=0.2475, acc=87.50%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 46/50:\n",
      "============================================================\n",
      "Train Loss: 0.0331 | Train Acc: 99.50%\n",
      "Val Loss:   0.5070 | Val Acc:   87.50%\n",
      "Learning Rate: 0.000013\n",
      "Time: 247.2s | Total: 191.7min\n",
      "‚è≥ Patience: 2/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:45<00:00,  1.22it/s, loss=0.0106, acc=99.41%]\n",
      "Epoch 47/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:23<00:00,  3.04it/s, loss=0.1915, acc=87.32%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 47/50:\n",
      "============================================================\n",
      "Train Loss: 0.0359 | Train Acc: 99.41%\n",
      "Val Loss:   0.5026 | Val Acc:   87.32%\n",
      "Learning Rate: 0.000013\n",
      "Time: 248.2s | Total: 195.8min\n",
      "‚è≥ Patience: 3/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:43<00:00,  1.23it/s, loss=0.0063, acc=99.32%]\n",
      "Epoch 48/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:22<00:00,  3.10it/s, loss=0.2139, acc=87.14%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 48/50:\n",
      "============================================================\n",
      "Train Loss: 0.0340 | Train Acc: 99.32%\n",
      "Val Loss:   0.5004 | Val Acc:   87.14%\n",
      "Learning Rate: 0.000013\n",
      "Time: 246.1s | Total: 199.9min\n",
      "‚è≥ Patience: 4/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:48<00:00,  1.20it/s, loss=0.0068, acc=99.32%]\n",
      "Epoch 49/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:23<00:00,  3.03it/s, loss=0.1874, acc=87.50%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 49/50:\n",
      "============================================================\n",
      "Train Loss: 0.0368 | Train Acc: 99.32%\n",
      "Val Loss:   0.4962 | Val Acc:   87.50%\n",
      "Learning Rate: 0.000013\n",
      "Time: 252.0s | Total: 204.1min\n",
      "‚è≥ Patience: 5/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 [Train]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 274/274 [03:47<00:00,  1.20it/s, loss=0.0716, acc=99.41%]\n",
      "Epoch 50/50 [Val]: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 70/70 [00:22<00:00,  3.06it/s, loss=0.1894, acc=87.32%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Citizen 100 - Epoch 50/50:\n",
      "============================================================\n",
      "Train Loss: 0.0391 | Train Acc: 99.41%\n",
      "Val Loss:   0.4996 | Val Acc:   87.32%\n",
      "Learning Rate: 0.000013\n",
      "Time: 250.3s | Total: 208.3min\n",
      "‚è≥ Patience: 6/10\n",
      "\n",
      "============================================================\n",
      "TRAINING COMPLETE\n",
      "============================================================\n",
      "\n",
      "üìä Best Results:\n",
      "   ‚Ä¢ Best Epoch: 44\n",
      "   ‚Ä¢ Best Val Acc: 87.68%\n",
      "   ‚Ä¢ Best Val Loss: 0.4974\n",
      "   ‚Ä¢ Total Time: 208.3 minutes\n",
      "\n",
      "üíæ Best model saved to:\n",
      "   /kaggle/working/WASL/models/checkpoints/best_model_100.pth\n",
      "\n",
      "‚úÖ Ready for Cell 18 - Fine-tune Citizen 100 ‚Üí WLASL100!\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------- Cell 19: Train on Citizen 100 Labels ----------\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING ON CITIZEN 100 LABELS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load FULL pre-trained model (architecture + weights)\n",
    "checkpoint_path = os.path.join(BASE_DIR, \"models\", \"checkpoints\", \"best_model_FULL.pth\")\n",
    "\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    print(\"‚ùå Error: WLASL100 FULL checkpoint not found!\")\n",
    "    print(\"   Please run Cell 1 to load the pre-trained model.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(f\"‚úÖ Loading FULL checkpoint: {checkpoint_path}\")\n",
    "print(\"   (Contains complete I3D model with architecture + weights)\")\n",
    "\n",
    "# Load the complete checkpoint (MUST use weights_only=False for full model)\n",
    "# InceptionI3d class is already defined in the previous cell\n",
    "checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)\n",
    "\n",
    "# Check what's in the checkpoint\n",
    "print(\"\\nüì¶ Checkpoint contents:\")\n",
    "for key in checkpoint.keys():\n",
    "    print(f\"   ‚Ä¢ {key}\")\n",
    "\n",
    "# Extract the FULL model object\n",
    "if 'model' in checkpoint:\n",
    "    model = checkpoint['model']\n",
    "    print(\"\\n‚úÖ Loaded FULL model object!\")\n",
    "    print(f\"   ‚Ä¢ Model type: {type(model).__name__}\")\n",
    "    print(f\"   ‚Ä¢ Validation accuracy: {checkpoint.get('val_acc', 75.15):.2f}%\")\n",
    "    print(\"   ‚Ä¢ Classes: 100\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Error: 'model' key not found in checkpoint!\")\n",
    "    print(f\"   Available keys: {list(checkpoint.keys())}\")\n",
    "    print(\"   Please make sure you uploaded the FULL model file.\")\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "# Move to device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "print(f\"\\n‚úÖ Model moved to: {device}\")\n",
    "print(\"   ‚Ä¢ Ready to train on Citizen 100!\")\n",
    "\n",
    "# Training config\n",
    "config_100 = {\n",
    "    'num_epochs': 50,\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 1e-8,\n",
    "    'adam_eps': 1e-3,\n",
    "    'patience': 10,\n",
    "    'grad_clip': 1.0,\n",
    "}\n",
    "\n",
    "print(\"\\nüìã Training configuration:\")\n",
    "for key, value in config_100.items():\n",
    "    print(f\"   ‚Ä¢ {key}: {value}\")\n",
    "\n",
    "# Optimizer\n",
    "optimizer_100 = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=config_100['learning_rate'],\n",
    "    weight_decay=config_100['weight_decay'],\n",
    "    eps=config_100['adam_eps']\n",
    ")\n",
    "\n",
    "scheduler_100 = ReduceLROnPlateau(\n",
    "    optimizer_100,\n",
    "    mode='min',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Checkpoint directory\n",
    "checkpoint_dir_100 = os.path.join(BASE_DIR, \"models\", \"checkpoints\")\n",
    "os.makedirs(checkpoint_dir_100, exist_ok=True)\n",
    "\n",
    "# Training history\n",
    "history_100 = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': [],\n",
    "    'lr': []\n",
    "}\n",
    "\n",
    "best_val_acc_100 = 0.0\n",
    "best_val_loss_100 = float('inf')\n",
    "best_epoch_100 = 0\n",
    "patience_counter_100 = 0\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"STARTING TRAINING\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "start_time_100 = time.time()\n",
    "\n",
    "for epoch in range(config_100['num_epochs']):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # TRAINING\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    train_pbar = tqdm(train_loader_100, desc=f\"Epoch {epoch+1}/{config_100['num_epochs']} [Train]\")\n",
    "    for batch_idx, batch in enumerate(train_pbar):\n",
    "        # FIX: Dataset already returns (C, T, H, W) and normalized [0, 1]\n",
    "        videos = batch['frames'].to(device)  # Already (B, C, T, H, W), float32, [0, 1]\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        optimizer_100.zero_grad()\n",
    "        outputs = model(videos)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), config_100['grad_clip'])\n",
    "        optimizer_100.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        train_correct += predicted.eq(labels).sum().item()\n",
    "        train_total += labels.size(0)\n",
    "        \n",
    "        train_pbar.set_postfix({\n",
    "            'loss': f\"{loss.item():.4f}\",\n",
    "            'acc': f\"{100.0 * train_correct / train_total:.2f}%\"\n",
    "        })\n",
    "    \n",
    "    train_loss /= len(train_loader_100)\n",
    "    train_acc = 100.0 * train_correct / train_total\n",
    "    \n",
    "    # VALIDATION\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        val_pbar = tqdm(val_loader_100, desc=f\"Epoch {epoch+1}/{config_100['num_epochs']} [Val]\")\n",
    "        for batch in val_pbar:\n",
    "            # FIX: Dataset already returns (C, T, H, W) and normalized [0, 1]\n",
    "            videos = batch['frames'].to(device)  # Already (B, C, T, H, W), float32, [0, 1]\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            outputs = model(videos)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            val_correct += predicted.eq(labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "            \n",
    "            val_pbar.set_postfix({\n",
    "                'loss': f\"{loss.item():.4f}\",\n",
    "                'acc': f\"{100.0 * val_correct / val_total:.2f}%\"\n",
    "            })\n",
    "    \n",
    "    val_loss /= len(val_loader_100)\n",
    "    val_acc = 100.0 * val_correct / val_total\n",
    "    \n",
    "    # Update scheduler\n",
    "    scheduler_100.step(val_loss)\n",
    "    current_lr = optimizer_100.param_groups[0]['lr']\n",
    "    \n",
    "    # Record history\n",
    "    history_100['train_loss'].append(train_loss)\n",
    "    history_100['train_acc'].append(train_acc)\n",
    "    history_100['val_loss'].append(val_loss)\n",
    "    history_100['val_acc'].append(val_acc)\n",
    "    history_100['lr'].append(current_lr)\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start\n",
    "    elapsed_time = time.time() - start_time_100\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Citizen 100 - Epoch {epoch+1}/{config_100['num_epochs']}:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.2f}%\")\n",
    "    print(f\"Learning Rate: {current_lr:.6f}\")\n",
    "    print(f\"Time: {epoch_time:.1f}s | Total: {elapsed_time/60:.1f}min\")\n",
    "    \n",
    "    # Check if best\n",
    "    is_best = val_acc > best_val_acc_100\n",
    "    \n",
    "    if is_best:\n",
    "        best_val_acc_100 = val_acc\n",
    "        best_val_loss_100 = val_loss\n",
    "        best_epoch_100 = epoch + 1\n",
    "        patience_counter_100 = 0\n",
    "        \n",
    "        # Save best model\n",
    "        best_model_path_100 = os.path.join(checkpoint_dir_100, \"best_model_100.pth\")\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer_100.state_dict(),\n",
    "            'scheduler_state_dict': scheduler_100.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc,\n",
    "            'history': history_100,\n",
    "            'num_classes': num_classes_100\n",
    "        }, best_model_path_100)\n",
    "        \n",
    "        print(f\"‚úÖ New best model saved! Val acc: {val_acc:.2f}%\")\n",
    "    else:\n",
    "        patience_counter_100 += 1\n",
    "        print(f\"‚è≥ Patience: {patience_counter_100}/{config_100['patience']}\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if patience_counter_100 >= config_100['patience']:\n",
    "        print(f\"\\n‚ö†Ô∏è Early stopping triggered after {epoch+1} epochs\")\n",
    "        break\n",
    "    \n",
    "    print()\n",
    "\n",
    "total_time = time.time() - start_time_100\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nüìä Best Results:\")\n",
    "print(f\"   ‚Ä¢ Best Epoch: {best_epoch_100}\")\n",
    "print(f\"   ‚Ä¢ Best Val Acc: {best_val_acc_100:.2f}%\")\n",
    "print(f\"   ‚Ä¢ Best Val Loss: {best_val_loss_100:.4f}\")\n",
    "print(f\"   ‚Ä¢ Total Time: {total_time/60:.1f} minutes\")\n",
    "\n",
    "print(\"\\nüíæ Best model saved to:\")\n",
    "print(f\"   {best_model_path_100}\")\n",
    "\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:05:18.733684Z",
     "iopub.status.busy": "2025-11-14T14:05:18.733027Z",
     "iopub.status.idle": "2025-11-14T14:05:18.857438Z",
     "shell.execute_reply": "2025-11-14T14:05:18.856765Z",
     "shell.execute_reply.started": "2025-11-14T14:05:18.733654Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "COPYING MODEL TO OUTPUT\n",
      "============================================================\n",
      "‚úÖ Model copied to output!\n",
      "üì¶ Size: 142.10 MB\n",
      "üì• Ready to download!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# copy to output root\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"COPYING MODEL TO OUTPUT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "source = '/kaggle/working/WASL/models/checkpoints/best_model_100.pth'\n",
    "\n",
    "if os.path.exists(source):\n",
    "    destination = '/kaggle/working/best_model_citizen100_87pct.pth'\n",
    "    shutil.copy(source, destination)\n",
    "    \n",
    "    print(\"‚úÖ Model copied to output!\")\n",
    "    print(f\"üì¶ Size: {os.path.getsize(destination) / 1024 / 1024:.2f} MB\")\n",
    "    print(\"üì• Ready to download!\")\n",
    "else:\n",
    "    print(\"‚ùå Model not found!\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T14:08:45.407852Z",
     "iopub.status.busy": "2025-11-14T14:08:45.407554Z",
     "iopub.status.idle": "2025-11-14T14:08:53.859562Z",
     "shell.execute_reply": "2025-11-14T14:08:53.858561Z",
     "shell.execute_reply.started": "2025-11-14T14:08:45.407831Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "COMPRESSING MODEL\n",
      "============================================================\n",
      "‚úÖ Model compressed successfully!\n",
      "üì¶ Original:   142.10 MB\n",
      "üóúÔ∏è  Compressed: 126.24 MB\n",
      "üíæ Saved:      11.2%\n",
      "üì• Download: /kaggle/working/best_model_citizen100_87pct.zip\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# compress model to zip\n",
    "import os\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"COMPRESSING MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "source_file = '/kaggle/working/best_model_citizen100_87pct.pth'\n",
    "zip_file = '/kaggle/working/best_model_citizen100_87pct.zip'\n",
    "\n",
    "if os.path.exists(source_file):\n",
    "    # Create zip file\n",
    "    with zipfile.ZipFile(zip_file, 'w', zipfile.ZIP_DEFLATED, compresslevel=9) as zipf:\n",
    "        zipf.write(source_file, os.path.basename(source_file))\n",
    "    \n",
    "    original_size = os.path.getsize(source_file) / 1024 / 1024\n",
    "    compressed_size = os.path.getsize(zip_file) / 1024 / 1024\n",
    "    compression_ratio = (1 - compressed_size / original_size) * 100\n",
    "    \n",
    "    print(\"‚úÖ Model compressed successfully!\")\n",
    "    print(f\"üì¶ Original:   {original_size:.2f} MB\")\n",
    "    print(f\"üóúÔ∏è  Compressed: {compressed_size:.2f} MB\")\n",
    "    print(f\"üíæ Saved:      {compression_ratio:.1f}%\")\n",
    "    print(f\"üì• Download: {zip_file}\")\n",
    "else:\n",
    "    print(\"‚ùå Model file not found!\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1589971,
     "sourceId": 2632847,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4178608,
     "sourceId": 7219693,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8649496,
     "sourceId": 13610789,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8658876,
     "sourceId": 13624060,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8731477,
     "sourceId": 13723748,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
